基本概念-内存管理-进程管理（创建）-调度算法-文件管理-io管理

- 局部性原理，它本来是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。

**介绍下系统调用**

系统调用是用户空间程序与内核之间的接口，它隐藏了底层硬件和操作系统内部的细节，提供了一种统一的、安全的方式来执行系统级别的任务。如文件操作、进程管理、网络通信等。

系统调用通常由用户空间程序通过软中断或硬中断的方式触发，从用户态切换到内核态执行。

**进程包括什么**（程序段，数据段，pcb）

pcb（进程id，进程状态，程序计数器，堆栈指针等），地址空间（代码，数据，bss，堆，栈），资源文件（打开的文件，网络连接等的文件描述符）

**1）进程间通信的方式**

管道，消息队列，共享内存，信号量，信号，socket

**2）进程能否共享内存**

各自的虚拟内存映射到同一块物理内存，要注意通过信号量，消息队列等同步机制访问共享内存，以避免数据冲突

**3）进程是如何做到资源隔离的**

进程独享地址空间，资源文件。操作系统的调度与保护机制（页面置换）。还可以加锁

**4）介绍下虚拟内存**+

虚拟内存是**一种在硬盘上模拟出来的内存**，把内存分成大小相同的页，通过页表完成虚拟内存和物理内存的映射，实现内存的**动态分配**和管理，实现内存隔离。使用时，每个程序操控自己的虚拟内存，然后去对应的物理内存中找，找到不到则发生**缺页异常，请求调页，页面置换**

- 优点：提供了比实际内存**更大**的地址空间，内存不足时可以实现内存交换，不常用的内存换出到磁盘，需要的时候换入到内存，支持内存管理和保护，提高了系统的稳定性和安全性。
- 缺点：增加了访问内存的时间，因为需要进行硬盘和内存的数据交换（页面置换），可能导致性能下降。

**请求调页**是指当程序访问的内存页不在物理内存中时，操作系统将其从硬盘加载到内存中。**页面置换**是指当内存中没有空闲页时，操作系统需要将某一页移出内存，腾出空间给新的页面。

补：虚拟内存、虚拟文件系统等「虚拟」的概念，本质上都是**向下屏蔽差异，向上提供统一的东西**，以方便我们程序员使用。

**5）进程开辟虚拟空间有哪些段？都用什么用？（虚拟内存结构）**

补：虚拟空间分内核态和用户态两部分，内核态共享，用户态独享，

用户态从下到上分为代码段，数据段，bss段，堆段，文件映射段，栈段

- 代码段，包括二进制可执行代码；
- 数据段，包括已初始化的静态常量和全局变量；
- BSS 段，包括未初始化的静态变量和全局变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等（下到上）
- 栈段，包括**局部变量和函数调用的上下文**等（上到下），栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小；

**6）虚拟地址是怎么转化到物理地址的**？	

cpu的内存管理单元负责，先查快表tlb，找不到再找正常页表，找到后找对应的页表项，通过页号加业内偏移完成映射

**虚拟内存**分成大小固定的**页**，**物理内存**也被分成同样大小的**页框**，**页表项**将虚拟页号映射到物理页框号，加上页内偏移确定具体地址，然后进行权限检查

补：TLB是计算机系统中的一个硬件缓存，用于加速虚拟地址到物理地址的转换过程，存储最近的一些虚拟地址到物理地址的映射，以便在进行地址翻译时快速找到对应关系，而不必每次都访问主存中的页表。

补：每个进程有自己的页表存在内存中，pcb中有一个指针指向页表，根据页表项查对应的物理内存，如果不存在或者是无效的（无效意味着不属于自己），产生一个缺页中断，发生请求调页，去磁盘中找到对应的页面，通过页面置换算法加载到内存中，并修改状态位为有效

**补：页表项字段**：页号，物理页号，状态位（是否属于自己或者说是否在内存中），访问字段（记录访问次数等信息用于页面置换算法），修改位（内存中的该页是否被修改过，如果没有被修改，置换该页时就不需要重新写回到磁盘上），硬盘地址（该页在硬盘的地址，请求调页时用到）

**7）分页与分段的概念，二者有何区别**？

- **分页（Paging）：** 将物理内存和逻辑内存分成固定**大小的页**，虚拟地址的页通过页表中的页表项映射到物理内存中的页框上。

  通过页号加页内偏移查找

  补：多级页表（时间换空间），因为页表一定要覆盖全部的虚拟地址空间，不分级要很大内存，分级后结合局部性原理，不一定需要创建每个一级页表对应的二级页表

- **分段（Segmentation）：** 将逻辑内存和物理内存分成**不定大小的段**（代码段，堆段，数据段，栈段），通过段号和段内偏移组成查找，存在内存碎片，内存不足时需要将大段数据交换到硬盘

##### **8）并发和并行的区别**

交替执行，时间片轮转实现。 同时执行，多核cpu实现

##### **9）进程的五个状态，状态间如何转换**

创建 就绪 运行（时间片用完） 终止 阻塞 （等待某一事件发生）挂起

补："挂起"（suspend）常常是一种**主动的、可控**的状态，通常由操作系统或程序自身的逻辑触发，sleep是挂起，意味着将一个进程或线程从内存中移动到外部存储（例如硬盘），使其暂时停止在运行时的状态。

**10）进程的控制结构**

pcb：进程id，进程状态，优先级，内存信息，资源信息（所使用的文件及io设备），寄存器的值，程序计数器的值，上下文信息

控制方法：链表将相同状态的pcb链在一起，状态发生变化则移动。	补：页表不在pcb中

**11）上下文切换 **

**什么是上下文切换：** 当操作系统决定暂停当前进程的执行，转而执行另一个进程时，**需要保存当前进程的上下文信息，然后加载下一个进程的上下文信息**，这个过程就是上下文切换。上下文包括：**虚拟内存，栈，全局变量等用户空间的资源和寄存器，内核堆栈等内核资源**，通常把取出的信息放入PCB，运行另一进程时，取出其PCB中上下文，加载到CPU，使进程继续执行

- 常见场景：时间片耗尽，阻塞等待资源，主动挂起，更高优先级抢占，硬件中断
- 进程、线程、协程的上下文切换：
  - **进程：** 虚拟内存、栈、全局变量（用户空间）内核堆栈，寄存器，程序计数器（内核空间）。
  - **线程：**虚拟内存公享，只保存私有数据，寄存器等不共享的数据
  - **协程：** 由程序员自行控制，上下文切换通常在代码中的特定位置进行，自定义保存和恢复的上下文信息。

**12）进程、线程、协程**（定义，创建，切换开销，上下文，通信）

- **进程（Process）：** 是操作系统**分配资源**的基本单位，具有独立的地址空间资源文件。

​	进程通信、共享数据困难，维护所需的系统开销大（创建，回收，上下文）	

- **线程（Thread）：** 是进程内的**一条执行流程**，共享进程的资源，但有独立的寄存器、栈。是**cpu调度**的基本单位

一个进程可以有多个线程，并发执行开销小（创建，终止，切换，数据传递不需要经过内核），一个线程崩溃导致所有线程崩溃（因为共享内存）

- **协程（Coroutine）：** 是一种**用户级（用户态）**的**轻量级**线程，由程序员自行控制调度，不依赖于操作系统的线程和进程。在特定的时机挂起（yield）和恢复（resume）执行，切换开销小

**13）进程的调度策略**

先来先服务（长作业有利），最短作业优先（短作业有利），高响应比（理想化算法，优先权=（等待时间+要求服务时间）/要求服务时间

时间片轮转（公平，但没有任务优先级），最高优先级（低优先级一直无法执行）

多级反馈（新进程第一级队尾，时间片用完没执行完，移到下一队列，优先级降低，但分配的时间片变长）

##### 14）进程间通信有哪些？

管道，（消息队列，共享内存，信号量），信号（通知发生了某个事件，只能实现简单通信，无法传递大量数据），socket

补：线程间通信的方式：共享进程内存，函数调用/全局变量，信号量，锁，屏障（多线程在某个点等待，全到达后再开始后续任务）

条件变量(满足某些条件进行线程的阻塞或唤醒)（生产者，消费者中的empty_buffer,full_buffer（直观的表示缓冲区是否满了））

协程间通信的方式：共享数据，消息传递，回调函数

通道（接发操作都是原子的，比方说发送消息需要访问共享资源，这个过程不会被接收消息的线程中断，反例生产者消费者）

补：RPC是一种协议（交互方法，数据格式，序列化反序列），允许程序调用远程服务器的方法像调用本地的一样，使分布式编程更加简单透明，socket是实现网络通信的基本手段，是传输层的一个工具，channel是一种通信的抽象，rpc可以基于channel实现

**15）同步、互斥、阻塞和非阻塞**+

同步是指**按照顺序**依次执行任务，一个任务完成后才能开始下一个任务（互相等待，互通消息）；

异步是指任务不按照顺序执行，可以同时执行多个任务，不需要等待前一个任务完成。（可以从应从从磁盘读文件的io角度来讲）

**本质上**就是，发出一个调用之后，没得到结果之前，是直接返回还是一直等待调用完成

互斥：同一时刻只有一个线程能访问资源（操作 A 和操作 B 不能在同一时刻执行）

阻塞：请求某个资源，资源不可用，线程被挂起，直到资源可用才能重新**等待cpu调度**

非阻塞：资源不可用，返回一个错误或特定的值，由程序源处理

**16）什么是临界区、临界资源**

- **临界区：** 可能有多线程访问共享资源的代码片段，会导致竞态条件，破坏数据的一致性。
- **临界资源：** 是指被多个线程共享的资源，在访问该资源时需要进行同步操作，以避免竞态条件。

**17）死锁，什么是死锁**

多个线程互相争夺资源，互相等待对方的锁，导致彼此无法继续进行

**死锁的四个必要条件    **互斥，持有并等待，不可剥夺，循环等待

**解决死锁的方法**   

- 破坏死锁的四个必要条件中的一个或多个。
- 资源分配图法：最常用的方法就是使用资源有序分配法。

**如何避免出现死锁，怎么排查？**

破坏四个条件，按固定顺序获得锁，避免嵌套锁，设置超时时间。工具辅助，分析线程日志，代码检查

**18**）**锁的种类及应用场景**

**互斥锁**（同一时刻只有一个线程可以访问临界区，加锁失败**释放cpu**给其他线程，自己进入阻塞态，线程切换涉及两次上下文切换，睡眠一次，唤醒一次）

**自旋锁**（**自旋锁**加锁失败后，线程会**忙等待**，直到它拿到锁。临界区小而短暂）（通过cpu的cas（*Compare And Swap*）指令实现）

需要抢占式的调度器在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU，不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式

自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：**当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对**。

**如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**

读写锁（适用于能明确区分读操作和写操作，读优先锁，写优先锁，公平读写锁）、以上都属于悲观锁信号量

乐观锁：先修改资源，再看这段时间内有没有发生共享资源的修改（有无冲突），有的话就放弃本次操作）（重试成本高，适合冲突概率低，锁成本高的场景）

补：CAS本身是乐观锁，但基于CAS实现的自旋锁是悲观锁（先看能否拿到锁，能的话改值加锁，然后改数据）

6.1

**19）页面置换算法，讲一下实现原理，请自己实现一个LRU**

页面置换算法的功能是，**当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面**，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页（请求调页）

1.最优页面（理想化2.先入先出3.最近最久未使用4.时钟页面置换（环形链表，一个指针，找到第一个未被访问的页）5.最不常用置换算法（选使用次数最少的）

创建和定位 ，访问过需要移到最前端，链表任意位置都可能被移动，map能定位要找的节点，不能定位前驱，所以需要双向链表

（节点储存k-v，map储存key和节点的位置）

**20）什么是守护进程，举几个例子，守护进程有什么作用**

守护进程是在后台运行的系统进程，独立于终端并且周期性地执行特定任务。它们通常不接受用户输入，守护进程的作用包括监控、日志记录等。常见的守护进程例子有系统日志守护进程和定时任务守护进程

**21）僵尸进程与孤儿进程**

- **僵尸进程：** 子进程先于父进程结束，但父进程没有及时处理子进程的退出状态，导致子进程的进程控制块仍然存在，但不再执行。
- **孤儿进程：** 父进程先于子进程结束，操作系统将子进程的父进程设置为init进程（进程ID为1），init进程会接管孤儿进程并完成其状态处理。

**22）计算机怎么去管理进程**

内核管理，pcb标识进程，储存进程状态，地址空间，上下文等，进程调度算法，通信，内存管理

**23）内核态下面分哪些模块或者子系统**

进程管理系统、内存管理系统、I/O管理系统和文件管理系统

**24）线程同步的方式**

锁（互斥，自旋，读写），信号量，屏障:让一组线程等待直到某条件才全部同时继续执行，条件变量（结合锁）

**25）中断**

（告诉cpu停止当前任务执行中断处理程序）

中断是计算机系统中的一种事件，它可以打断正常的程序执行，转而执行相应的中断处理程序。中断可以是硬件产生的（如I/O完成、时钟中断）或者软件产生的（通过系统调用或异常触发）。

**26）鸵鸟策略**

不处理问题、忽视问题的应对方式，类似鸵鸟把头埋在沙土中以逃避危险的行为。

**27）银行家算法**

判断系统资源是否能满足进程的最大需求，从而避免分配资源导致系统进入不可恢复的死锁状态

**29）内核态和用户态的区别，二者具备的资源**+

区别在于程序运行时所拥有的特权级别和访问权限，用户态独享自己的内存，内核态共享全部内存

如程序在用户态运行，只能访问自己的内存空间，无法访问内核空间，无法执行特权指令，如io等

内核态则可以访问全部内存和所有硬件资源，进行系统级别的操作，如进程管理，内存分配等

**为什么要分用户态和内核态**+

增强系统安全性，隔离敏感资源，防止恶意程序破坏或程序与程序间造成不可控的影响，便于维护扩展

**28）何时会发生内核态和用户态的切换**+

系统调用，中断，异常

系统调用：用户请求某些特权操作，如io，打开文件，进程管理，一般通过软硬中断触发

中断：硬件或外部设备触发，如时钟中断，io中断

异常：程序执行中发生了错误信息，如内存访问越界，非法指令，浮点运算溢出

系统调用（需要调用硬件如cpu，线程创建撤销（用户请求，内核实现分配内存，创建pcb等）线程调度，睡眠唤醒线程，io完成）、异常和外部中断（如硬件中断）

**30）协程的优缺点**

- **优点：** 轻量级，减少了线程切换的开销，提高了程序的执行效率。由程序员控制，更灵活，适用于异步编程和高并发场景。
- **缺点：** 无法利用多核处理器的并行性，只能在单个线程内执行。需要程序员自行处理协程之间的通信和同步问题

**31）多线程中遇到的问题，如何解决，如何debug多线程遇到的问题**

资源竞争，死锁，内存泄漏（分配完内存，使用完成后没有释放）。日志，打断点？使用多线程调试工具，跟踪和分析线程的执行流程，检查变量的值，定位问题的发生点，以及使用日志输出等方式进行排查

**32）分时操作系统和非分时操作系统的区别**

- **分时操作系统（Time-Sharing System）：** 多用户、多任务的操作系统，它能够在多个任务间进行切换，每个用户感觉到自己在独占使用计算机。
- **非分时操作系统：** 单用户、单任务的操作系统，每次只能运行一个程序，用户与计算机的交互是独占性的。

**33）64位和32位的区别**

cpu：一次可计算64为数字，总线是64条

操作系统：寻址空间64位

软件：指令是64位的

**34）电脑 4GB内存，我申请 5GB内存可以吗？**

32位系统最大只能操作32位地址，所以进程最大只能申请3GB内存（4=3+1），直接申请5GB会失效。而64位可以，申请虚拟内存后，如果需要访问物理内存，而物理内存空间不足会发生页面置换，把原来的页面放到磁盘

**35）线程的分类**

- **内核级线程：** 由操作系统内核管理的线程，线程的创建、撤销、调度等都由内核负责。
- **用户级线程：** 由用户空间的线程库管理的线程，线程的创建、调度等都由用户程序控制，操作系统对其一无所知。

**36）什么是IO多路复用，有哪些方式实现IO多路复用**

基本socket是同步阻塞的，一时间只能处理一个客户端请求，如果与一个客户端的正在发生io或阻塞，其他客户端无法建立连接，所以需要多线程模型，一个线程去监听，多个线程去处理io，但这样会占用很多资源。

后来采用多进程/线程，一个socket对应一个线程，但是这样频繁创建销毁，资源消耗大，难以达到c10k

IO多路复用就是**一个进程处理多个I/O流**，所有socket放到文件描述符集合统一管理，通过系统调用监听io流状态，发生事件通知进程处理，处理过程类似cpu调度，如每个请求处理1ms，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。

具体的实现有select、poll（线性储存，两次遍历，两次拷贝）和epoll（内核红黑树，只传入新连接，传出发生事件的连接）

**补：**每个连接都需要线程去处理业务（读写等），给每个连接都创建一个线程开销大，所以使用线程池，引入线程池就需要知道当前连接是否有数据可读，如果用socket的阻塞io，就没法去处理别的任务，如果用非阻塞（NIO），就需要cpu不断轮询，看有无事件发生，为了解决这个问题，用一个**监控线程**监控所有socket，连接上有数据，从线程池拿到一个线程，去处理

**补（好好好）：**一个服务器会与多个客户端建立连接，会有多个socket，所以希望一个进程同时处理多个io（可以理解为监听多个socket的文件描述符），即io多路复用，具体的实现有select/poll，epoll，多路复用是事件驱动，把所有socket放一起（epoll是红黑树+链表），发生事件会触发epollwait苏醒，拿去处理，这就产生了两种触发方式，水平触发和边缘触发，水平触发只要还有事件未得到处理就让epoll_wait苏醒，边缘触发只有在事件发生那一时刻让epollwait苏醒一次，效率更高

**补：**Reactor 模式则是对io多路复用做的封装

**补：**netty是对 Socket 的封装，非阻塞的事件驱动的网络应用框架

**37）介绍一下常见的IO模型**，结合38一起看

- **阻塞IO模型（BIO）：** 进程或线程在执行IO操作时被阻塞，直到IO操作完成才能继续执行。（指内核准备好数据之前）
- **非阻塞IO模型（NIO）：** 进程或线程在执行IO操作时不会被阻塞，立即返回，但需要轮询IO操作的状态，效率较低。
- **异步IO模型（AIO）：** 进程或线程发起IO请求后，可以继续执行其他任务，IO操作完成后，系统通知。（内核自动将数据拷贝到用户）
- **IO多路复用模型（IO Multiplexing）：** 通过select、poll、epoll等机制，一个进程或线程可以同时监听多个文件描述符，实现多个IO操作。

补：网络高性能的原因：基于io多路复用实现的reactor模式，同时监听多个事件，根据事件类型分配给某个进程、线程

补：**IO分为两个阶段**：数据准备阶段和数据拷贝阶段；BIO需要等待数据准备和数据拷贝；NIO会轮询数据是否准备完成，需要等待数据拷贝；AIO会在数据准备完成和数据拷贝完成后收到通知，然后执行异步处理逻辑

数据准备：硬盘到内核，数据拷贝：内核到应用

这是因为应用只能操作用户区，进行io需要发起系统调用，等待内核区把数据拷进用户区

**38）BIO 和 NIO 的区别？**

阻塞和非阻塞指是否等待数据从**磁盘拷贝到内核**这个过程，但是nio模型中，应用程序会一直发起read调用（轮询，消耗cpu资源，同时这个过程还涉及到系统调用，因为需要问内核准没准备好），同时，内核拷贝到用户这一过程仍然是阻塞的。

进而产生了io多路复用，**减少无效的系统调用，减少了对 CPU 资源的消耗。**把socket注册到内核管理，然后准备就绪了，内核通知应用，应用再read，但是内核拷贝数据到应用这个过程仍然是需要阻塞的

进而产生了aio，read之后直接返回，内核拷贝完了回调通知应用程序进行后续操作

**39）select poll epoll定义，区别**

这三个函数都是实现I/O多路复用的方式，它们可以监视多个文件描述符，判断它们中的哪些文件描述符可以进行I/O操作。

把socket放到文件描述符集合统一管理

- **select**：是最早出现的函数，可监视的文件描述符数量有限，通常默认是1024，map储存。
- **poll**：改进了select的限制，没有数量限制，但是仍然要遍历所有文件描述符，链表储存。
- **epoll**：是Linux特有的高性能I/O复用机制，使用事件通知的方式，只返回活跃的文件描述符，减少了遍历的开销，适合高并发的场景。内核红黑树保存所有socket，同时维护一个链表记录就绪时间，来新连接加入红黑树，发生事件回调，把事件加入到就绪事件列表，epoll_wait返回

select和poll都需要对socket遍历和拷贝（用户拷到内核，内核监听，遍历看是哪个发生事件，标记，拷贝回用户，用户再遍历）

epoll红黑树存在内核里，不用来回拷贝，维护一个链表储存就绪事件，只把有事件的socket传给应用，不需要遍历

只有epoll支持边缘触发

补：epoll流程：创建epoll 对象，将需要监控的socket注册到epoll对象中，调用 epoll_wait 函数，进入阻塞状态，等待文件描述符上的事件发生，一旦有事件发生，从epoll_wait中苏醒，应用处理事件

补：新连接发生时，监听socket中发生事件，使epoll苏醒，accept拿到新的socket，并将其注册到epoll中，以便后续监控这个新连接上的事件

**39）零拷贝与大文件传输**

传输大文件需要异步io+直接io（不使用pageCache），

零拷贝需要缓存io（pageCache）（readFile函数，磁盘通过dma拷贝到内核内存PageCache，把文件描述符和大小传给socket，网卡dma从Pagecache拿到文件发送）（零拷贝全过程没有用到cpu搬运数据，用的都是DMA）

kafka就用了零拷贝

补：磁盘高速缓冲区PageCache是分配给内核的一块内存区域。这个缓冲区用于存储磁盘数据的副本，以提高对磁盘的访问性能。

他的主要优点有两个1.缓存最近被访问的数据2.预读功能

**40）IO事件的水平触发和边缘触发（LT和ET）**

他们是io事件的两种触发模式，一般与非阻塞io搭配使用

- **水平触发（LT）**：当socket有可读或可写事件发生时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**。
- **边缘触发（ET）**：发生事件时，如果应用程序没有处理数据，不会再次收到通知，直到状态再次发生变化。**服务器端只会从 epoll_wait 中苏醒一次**，效率更高。只有发生事件时醒一次，所以需要尽可能的去读写，防止错失数据，循环的去读，配合非阻塞io，没数据可读时返回一个错误。

**Reactor结构**

 I/O 多路复用是面向过程的，后来基于面向对象的思想，对 I/O 多路复用作了一层封装，让使用者不用考虑底层网络 API 的细节，只需要关注应用代码的编写，就是reactor模式

 reactor对象通过select（io多路复用接口）监听事件，收到事件后通过dispatch分发，根据事件类型分发到acceptor（用于建立连接）或是handler（处理后续响应）

**41）reactor的三种模型**

- **单线程单Reactor**：一个线程处理所有的I/O事件，性能有限，无法充分利用多核cpu，业务耗时长会导致响应延迟。
- **多线程单Reactor**：主线程创建连接，监听事件，回复响应，创建子线程处理事件（一个reactor承担所有事件的监听和响应）
- **多线程多Reactor**：主线程main_reactor负责创建，接受新连接，监听到事件后将连接分配给子线程，子线程获取连接并继续监听，并创建一个handler用于处理连接的响应事件。

**Reactor和NIO的关系**、

**非阻塞io：**如果没有数据可读取或写入，IO操作不会阻塞当前线程或进程，而是立即返回一个错误或标记，告诉程序当前的IO操作无法立即完成。这样，程序可以继续执行其他任务，而不必等待IO操作完成。

处理连接上的事件需要线程，不希望频繁创建销毁，引入线程池，一般socket默认非阻塞io，这样没数据可读不确定是事办完了还是暂时等待，如果改为非阻塞需要轮询判断是否有数据过来，消耗cpu，所以希望能直接知道线程上是否有数据，方法就是多路复用，

所以非阻塞io+io多路复用+线程池 = reactor模式

reactor和handler组成，epoll监听多个socket，配合边缘触发，nio，一直读socket事件

**什么是一致性哈希**

1.负载均衡：客户端请求如何分配给服务器集群（轮询，加权轮询），

此方法不适用分布式系统（数据分片的体统），如何确定某个k应该在哪个节点获得，需要一种适合分布式系统的负载均衡算法

可以使用哈希算法，但哈希算法在扩容或缩容时会改变大部分映射关系，需要大量迁移数据

所以有了一致性哈希，一般哈希对节点数量取模，判断数据储存位置，一致性哈希对2的32次方取模，将节点和数据都映射到一个哈希环上，对数据进行哈希映射，选择顺时针第一个节点作为储存节点，因此增加或删除节点只会影响后续第一个节点的储存

但是不能保证节点在哈希环上均匀分配，又引入了虚拟节点提高均衡度，同时节点变化时会由不同节点共同分担，减少对后继节点的影响，同时对配置更好的节点曾加虚拟节点数量，就可实现权重
