基本概念-内存管理-进程管理（创建）-调度算法-文件管理-io管理

- 局部性原理，它本来是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。

  句柄：一个抽象的概念，可以指向任何对象、资源的指针

  文件描述符：内核为了标识一个打开的文件而分配给进程的索引值，用于文件相关的操作

**介绍下系统调用**

系统调用是用户空间程序与内核之间的接口，它隐藏了底层硬件和操作系统内部的细节，提供了一种统一的、安全的方式来执行系统级别的任务。如文件操作、进程管理、网络通信等。

系统调用通常由用户空间程序通过软中断或硬中断的方式触发，从用户态切换到内核态执行。

**进程包括什么**（程序段，数据段，pcb）

pcb（进程id，进程状态，程序计数器，堆栈指针等），地址空间（代码，数据，bss，堆，栈），资源文件（打开的文件，网络连接等的文件描述符）

**1）进程间通信的方式**

管道，消息队列，共享内存，信号量，信号，socket

**2）进程能否共享内存**

各自的虚拟内存映射到同一块物理内存，要注意通过信号量，消息队列等同步机制访问共享内存，以避免数据冲突

**3）进程是如何做到资源隔离的**

进程独享地址空间，资源文件。操作系统的调度与保护机制（页面置换）。还可以加锁

##### **虚拟内存**

虚拟内存是**一种在硬盘上模拟出来的内存**，把内存分成大小相同的页，通过页表完成虚拟内存和物理内存的映射，实现内存的**动态分配**和管理，实现内存隔离。使用时，每个程序操控自己的虚拟内存，然后去对应的物理内存中找，找到不到则发生**缺页异常，请求调页，页面置换**

- 优点：提供了比实际内存**更大**的地址空间，内存不足时可以实现内存交换，不常用的内存换出到磁盘，需要的时候换入到内存，支持内存管理和保护，提高了系统的稳定性和安全性。
- 缺点：增加了访问内存的时间，因为需要进行硬盘和内存的数据交换（页面置换），可能导致性能下降。

**请求调页**是指当程序访问的内存页不在物理内存中时，操作系统将其从硬盘加载到内存中。**页面置换**是指当内存中没有空闲页时，操作系统需要将某一页移出内存，腾出空间给新的页面。

补：虚拟内存、虚拟文件系统等「虚拟」的概念，本质上都是**向下屏蔽差异，向上提供统一的东西**，以方便我们程序员使用。

##### 虚拟到物理的转换

目的：空间隔离，操作统一管理

途径：页表，页号加页内偏移；多级页表，页面置换

把虚拟内存和物理内存都分成大小固定的页

一级页表能完全映射到4gb，二级页表只有需要时才创建

进程访问的虚拟地址在页表中查不到，产生缺页异常，发起请求调页，内核分配空间，更新页表，最后返回用户空间，恢复进程执行

映射之后不一定需要立即把页加载到物理内存，可以需要时再加

**页面置换算法，讲一下实现原理，请自己实现一个LRU**

页面置换算法的功能是，**当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面**，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页（请求调页）

1.最优页面（理想化)

2.先入先出

3.最近最久未使用

5.最不常用置换算法（选使用次数最少的）

4.时钟页面置换

页面保存为环形链表，有一个访问位；访问哪个页面，就指到哪个页面，访问位置1；

缺页时，

- 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
- 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

**进程开辟虚拟空间有哪些段？都用什么用？（虚拟内存结构）**

补：虚拟空间分内核态和用户态两部分，内核态共享，用户态独享

内核区地址高位

高 -》内核 - 》栈 -》 堆 -》 数据 -》 代码 0》 低

用户态从下到上分为代码段，数据段，bss段，堆段，文件映射段，栈段

栈从上往下写，堆从下往上写，防溢出

- 代码段，包括二进制可执行代码；
- 数据段，包括已初始化的静态常量和全局变量；
- BSS 段，包括未初始化的静态变量和全局变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等（下到上）
- 栈段，包括**局部变量和函数调用的上下文**等（上到下），栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小；

**虚拟地址是怎么转化到物理地址的**？	

cpu的内存管理单元负责，先查快表tlb，找不到再找正常页表，找到后找对应的页表项，通过页号加业内偏移完成映射

**虚拟内存**分成大小固定的**页**，**物理内存**也被分成同样大小的**页框**，**页表项**将虚拟页号映射到物理页框号，加上页内偏移确定具体地址，然后进行权限检查

补：TLB是计算机系统中的一个硬件缓存，用于加速虚拟地址到物理地址的转换过程，存储最近的一些虚拟地址到物理地址的映射，以便在进行地址翻译时快速找到对应关系，而不必每次都访问主存中的页表。

补：每个进程有自己的页表存在内存中，pcb中有一个指针指向页表，根据页表项查对应的物理内存，如果不存在或者是无效的（无效意味着不属于自己），产生一个缺页中断，发生请求调页，去磁盘中找到对应的页面，通过页面置换算法加载到内存中，并修改状态位为有效

**补：页表项字段**：页号，物理页号，状态位（是否属于自己或者说是否在内存中），访问字段（记录访问次数等信息用于页面置换算法），修改位（内存中的该页是否被修改过，如果没有被修改，置换该页时就不需要重新写回到磁盘上），硬盘地址（该页在硬盘的地址，请求调页时用到）

**7）分页与分段的概念，二者有何区别**？

- **分页（Paging）：** 将物理内存和逻辑内存分成固定**大小的页**，虚拟地址的页通过页表中的页表项映射到物理内存中的页框上。

  通过页号加页内偏移查找

  补：多级页表（时间换空间），因为页表一定要覆盖全部的虚拟地址空间，不分级要很大内存，分级后结合局部性原理，不一定需要创建每个一级页表对应的二级页表

- **分段（Segmentation）：** 将逻辑内存和物理内存分成**不定大小的段**（代码段，堆段，数据段，栈段），通过段号和段内偏移组成查找，存在内存碎片，内存不足时需要将大段数据交换到硬盘

##### **8）并发和并行的区别**

交替执行，时间片轮转实现。 同时执行，多核cpu实现

##### **9）进程的五个状态，状态间如何转换**

创建 就绪 运行（时间片用完） 终止 阻塞 （等待某一事件发生）挂起

补："挂起"（suspend）常常是一种**主动的、可控**的状态，通常由操作系统或程序自身的逻辑触发，sleep是挂起，意味着将一个进程或线程从内存中移动到外部存储（例如硬盘），使其暂时停止在运行时的状态。

**10）进程的控制结构**

pcb：进程id，进程状态，优先级，内存信息，资源信息（所使用的文件及io设备），寄存器的值，程序计数器的值，上下文信息

控制方法：链表将相同状态的pcb链在一起，状态发生变化则移动。	补：页表不在pcb中

**11）上下文切换 **

**什么是上下文切换：** 当操作系统决定暂停当前进程的执行，转而执行另一个进程时，**需要保存当前进程的上下文信息，然后加载下一个进程的上下文信息**，这个过程就是上下文切换。上下文包括：**虚拟内存，栈，全局变量等用户空间的资源和寄存器，内核堆栈等内核资源**，通常把取出的信息放入PCB，运行另一进程时，取出其PCB中上下文，加载到CPU，使进程继续执行

- 常见场景：时间片耗尽，阻塞等待资源，主动挂起，更高优先级抢占，硬件中断
- 进程、线程、协程的上下文切换：
  - **进程：** 虚拟内存、栈、全局变量（用户空间）内核堆栈，寄存器，程序计数器（内核空间）。
  - **线程：**虚拟内存公享，只保存私有数据，寄存器等不共享的数据
  - **协程：** 由程序员自行控制，上下文切换通常在代码中的特定位置进行，自定义保存和恢复的上下文信息。

##### 进程和线程

**12）进程、线程、协程**（定义，创建，切换开销，通信）

进程（Process）：一个运行起来的程序， 是操作系统**分配资源**的基本单位，具有独立的地址空间资源文件(页表)，创建销毁所需的系统开销大，上下文切换开销大，通信更困难，

线程（Thread）： 是进程内的**一条执行流程**，共享进程的资源，但有独立的寄存器、栈。是**cpu调度**的基本单位

一个进程可以有多个线程，并发执行开销小（创建，终止，切换，数据传递不需要经过内核），一个线程崩溃导致所有线程崩溃（因为共享内存）

**协程（Coroutine）：** 是一种**用户级（用户态）**的**轻量级**线程，由程序员自行控制调度，不依赖于操作系统的线程和进程。在特定的时机挂起（yield）和恢复（resume）执行，切换开销小

##### **进程的调度策略**

先来先服务（长作业有利），最短作业优先（短作业有利），高响应比（理想化算法，优先权=（等待时间+要求服务时间）/要求服务时间

时间片轮转（公平，但没有任务优先级），最高优先级（低优先级一直无法执行）

多级反馈（新进程第一级队尾，时间片用完没执行完，移到下一队列，优先级降低，但分配的时间片变长）

##### 线程如何得知时间片用完

线程本身并不能直接感知时间片是否用完，而是由操作系统负责监控和控制

调度器会从就绪队列拿一个线程，给他分配cpu资源，操作系统会配合硬件时钟给cpu发中断信号，cpu把线程重新放到队列，等待下一次执行，然后上下文切换

#### 进程间通信有哪些？

管道，（消息队列，共享内存，信号量），信号（通知发生了某个事件，只能实现简单通信，无法传递大量数据），socket



信号是一种异步的通信机制，用于通知进程发生了某个特定的事件。信号可以由操作系统内核、其他进程或用户程序发送给目标进程。

信号是异步的，信号发生，操作系统会中断目标进程正常流程，执行信号处理函数；进程可以通过系统调用注册信号处理函数，以处理不同类型的信号。

##### 管道

本质上都是把数据缓存在内核，与消息队列区别在于，消息没读完，写端会阻塞，而消息队列写完就直接返回了

命名管道在内核有个文件，类型为pipe，不相关进程也能通信

匿名管道要通过fork创建子进程，然后复制文件描述符实现通信，向shell中的`|`，就是shell创建了一个匿名管道，然后创建了两个shell的子进程



补：线程间通信的方式：共享进程内存，函数调用/全局变量，信号量，锁，屏障（多线程在某个点等待，全到达后再开始后续任务）

条件变量(满足某些条件进行线程的阻塞或唤醒)（生产者，消费者中的empty_buffer,full_buffer（直观的表示缓冲区是否满了））

协程间通信的方式：共享数据，消息传递，回调函数

通道（接发操作都是原子的，比方说发送消息需要访问共享资源，这个过程不会被接收消息的线程中断，反例生产者消费者）

补：RPC是一种协议（交互方法，数据格式，序列化反序列），允许程序调用远程服务器的方法像调用本地的一样，使分布式编程更加简单透明，socket是实现网络通信的基本手段，是传输层的一个工具，channel是一种通信的抽象，rpc可以基于channel实现



**15）同步、互斥、阻塞和非阻塞**+

同步是指**按照顺序**依次执行任务，一个任务完成后才能开始下一个任务（互相等待，互通消息）；

异步是指任务不按照顺序执行，可以同时执行多个任务，不需要等待前一个任务完成。（可以从应从从磁盘读文件的io角度来讲）

**本质上**就是，发出一个调用之后，没得到结果之前，是直接返回还是一直等待调用完成

互斥：同一时刻只有一个线程能访问资源（操作 A 和操作 B 不能在同一时刻执行）

阻塞：请求某个资源，资源不可用，线程被挂起，直到资源可用才能重新**等待cpu调度**

非阻塞：资源不可用，返回一个错误或特定的值，由程序源处理

**16）什么是临界区、临界资源**

- **临界区：** 可能有多线程访问共享资源的代码片段，会导致竞态条件，破坏数据的一致性。
- **临界资源：** 是指被多个线程共享的资源，在访问该资源时需要进行同步操作，以避免竞态条件。

#### 死锁

多个线程互相争夺资源，互相等待对方的锁，导致彼此无法继续进行

**死锁的四个必要条件    **互斥，持有并等待，不可剥夺，循环等待

**解决死锁的方法**   

- 破坏死锁的四个必要条件中的一个或多个。
  - 破坏互斥，让资源可以共享
  - 破坏持有并等待，申请新资源先释放已有资源；一次性申请所有需要的资源
  - 优先级较高的线程可以剥夺优先级较低线程的资源
  - 按固定顺序获得锁；资源分配图法：最常用的方法就是使用资源有序分配法。
  - 设置超时时间，申请资源时等待一定时间后自动释放已占有的资源并重新尝试
  - 工具辅助，分析线程日志，代码检查，即死锁检测与恢复，定期检查系统是否出现死锁，若出现则通过回滚、杀死线程等手段恢复


**18**）**锁的种类及应用场景**

**互斥锁**（同一时刻只有一个线程可以访问临界区，加锁失败**释放cpu**给其他线程，自己进入阻塞态，线程切换涉及两次上下文切换，睡眠一次，唤醒一次）

**自旋锁**（**自旋锁**加锁失败后，线程会**忙等待**，直到它拿到锁。临界区小而短暂）（通过cpu的cas（*Compare And Swap*）指令实现）

需要抢占式的调度器在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU，不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式

自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：**当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对**。

**如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**

读写锁（适用于能明确区分读操作和写操作，读优先锁，写优先锁，公平读写锁）、以上都属于悲观锁信号量

乐观锁：先修改资源，再看这段时间内有没有发生共享资源的修改（有无冲突），有的话就放弃本次操作）（重试成本高，适合冲突概率低，锁成本高的场景）

补：CAS本身是乐观锁，但基于CAS实现的自旋锁是悲观锁（先看能否拿到锁，能的话改值加锁，然后改数据）

6.1



**20）什么是守护进程，举几个例子，守护进程有什么作用**

守护进程是在后台运行的系统进程，独立于终端并且周期性地执行特定任务。它们通常不接受用户输入，守护进程的作用包括监控、日志记录等。常见的守护进程例子有系统日志守护进程和定时任务守护进程

**21）僵尸进程与孤儿进程**

- **僵尸进程：** 子进程先于父进程结束，但父进程没有及时处理子进程的退出状态，导致子进程的进程控制块仍然存在，但不再执行。
- **孤儿进程：** 父进程先于子进程结束，操作系统将子进程的父进程设置为init进程（进程ID为1），init进程会接管孤儿进程并完成其状态处理。

**22）计算机怎么去管理进程**

内核管理，pcb标识进程，储存进程状态，地址空间，上下文等，进程调度算法，通信，内存管理

**23）内核态下面分哪些模块或者子系统**

进程管理系统、内存管理系统、I/O管理系统和文件管理系统

**24）线程同步的方式**

锁（互斥，自旋，读写），信号量，屏障:让一组线程等待直到某条件才全部同时继续执行，条件变量（结合锁）

**25）中断**

（告诉cpu停止当前任务执行中断处理程序）

中断是计算机系统中的一种事件，它可以打断正常的程序执行，转而执行相应的中断处理程序。中断可以是硬件产生的（如I/O完成、时钟中断）或者软件产生的（通过系统调用或异常触发）。

**26）鸵鸟策略**

不处理问题、忽视问题的应对方式，类似鸵鸟把头埋在沙土中以逃避危险的行为。

**27）银行家算法**

判断系统资源是否能满足进程的最大需求，从而避免分配资源导致系统进入不可恢复的死锁状态

**29）内核态和用户态的区别，二者具备的资源**+

区别在于程序运行时所拥有的特权级别和访问权限，用户态独享自己的内存，内核态共享全部内存

如程序在用户态运行，只能访问自己的内存空间，无法访问内核空间，无法执行特权指令，如io等

内核态则可以访问全部内存和所有硬件资源，进行系统级别的操作，如进程管理，内存分配等

**为什么要分用户态和内核态**+

增强系统安全性，隔离敏感资源，防止恶意程序破坏或程序与程序间造成不可控的影响，便于维护扩展

**28）何时会发生内核态和用户态的切换**+

系统调用，中断，异常

系统调用：用户请求某些特权操作，如io，打开文件，进程管理，一般通过软硬中断触发

中断：硬件或外部设备触发，如时钟中断，io中断

异常：程序执行中发生了错误信息，如内存访问越界，非法指令，浮点运算溢出

系统调用（需要调用硬件如cpu，线程创建撤销（用户请求，内核实现分配内存，创建pcb等）线程调度，睡眠唤醒线程，io完成）、异常和外部中断（如硬件中断）

**30）协程的优缺点**

- **优点：** 轻量级，减少了线程切换的开销，提高了程序的执行效率。由程序员控制，更灵活，适用于异步编程和高并发场景。
- **缺点：** 无法利用多核处理器的并行性，只能在单个线程内执行。需要程序员自行处理协程之间的通信和同步问题

**31）多线程中遇到的问题，如何解决，如何debug多线程遇到的问题**

资源竞争，死锁，内存泄漏（分配完内存，使用完成后没有释放）。日志，打断点？使用多线程调试工具，跟踪和分析线程的执行流程，检查变量的值，定位问题的发生点，以及使用日志输出等方式进行排查

**32）分时操作系统和非分时操作系统的区别**

- **分时操作系统（Time-Sharing System）：** 多用户、多任务的操作系统，它能够在多个任务间进行切换，每个用户感觉到自己在独占使用计算机。
- **非分时操作系统：** 单用户、单任务的操作系统，每次只能运行一个程序，用户与计算机的交互是独占性的。

**33）64位和32位的区别**

cpu：一次可计算64为数字，总线是64条

操作系统：寻址空间64位

软件：指令是64位的

**34）电脑 4GB内存，我申请 5GB内存可以吗？**

32位系统最大只能操作32位地址，所以进程最大只能申请3GB内存（4=3+1），直接申请5GB会失效。而64位可以，申请虚拟内存后，如果需要访问物理内存，而物理内存空间不足会发生页面置换，把原来的页面放到磁盘

**35）线程的分类**

- **内核级线程：** 由操作系统内核管理的线程，线程的创建、撤销、调度等都由内核负责。
- **用户级线程：** 由用户空间的线程库管理的线程，线程的创建、调度等都由用户程序控制，操作系统对其一无所知。

#### 文件描述符

每一个进程都有一个数据结构 `task_struct`，该结构体里有一个指向「文件描述符数组」的成员指针。

数组的内容是一个指针，指向内核中该进程所有打开的文件的列表，数组的下标就是文件描述符，是一个整数，也就是说内核可以通过文件描述符找到对应打开的文件。

### IO

#### mmap，sendfile，零拷贝

正常 read+write 两次系统调用(四次上下文切换)，两次DMA拷贝，两次CPU拷贝

​	从磁盘拷到内核（dma），内核拷到应用（cpu），然后应用拷到socket缓冲区，socket缓冲区拷到网卡，4次上下文切换，两次cpu拷贝

```java
read(file, tmp_buf, len);
write(socket, tmp_buf, len);
```

+ **mmap+write：**代替read，减少一次cpu拷贝

​	mmap：memory - map，内存映射，让应用像访问自身内存一样访问内核数据

​	把内核数据映射到应用(实际仍在内核，但应用区可读)，可以减少一次拷贝，但仍涉及两次系统调用

​	read类似于要把内核区数据拷到应用层，mmap直接用了个映射，虽说也是操作自己的空间，但会指向内核真实数据区。之后再执行write

```java
buf = mmap(file, len);
write(sockfd, buf, len);
```

+ **零拷贝**

零拷贝要求必须用pageCache

sendfile：就是一种零拷贝，一次系统调用，一次cpu拷贝

磁盘通过dma拷贝到内核内存PageCache，把文件描述符和大小传给socket，网卡dma从Pagecache拿到文件发送

零拷贝全过程没有用到cpu搬运数据，用的都是DMA

```c++
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度
返回值是实际复制数据的长度
```

补：每个 I/O 设备都有自己的 DMA 控制器，

dma实际上就是个控制器，知道数据从哪来到哪去

#### pageCache(缓存io)

零拷贝一定有pageCache，但不是所有文件收发都会用到pageCache（数据库用，kafka用）

如directIO，一般绕开 PageCache 的 I/O 叫直接 I/O，使用 PageCache 的 I/O 则叫缓存 I/O。

如： 网卡 → ringbuffer → 某个具体内核 Socket → 用户空间 更为常见，

文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是磁盘高速缓存（PageCache）

即把磁盘中一部分数据存到内存，具体存什么？

他的主要优点有两个：

局部性原理缓存最近被访问的数据 + 顺序io实现预读

如果数据只被读了一次，缓存也就失去了意义，反而带来了额外开销

所以适合小文件，随机读写场景

![image-20250217205116750](C:\Users\16776\AppData\Roaming\Typora\typora-user-images\image-20250217205116750.png)

#### 直接io(大文件传输)

直接 I/O 是在用户空间和磁盘等设备之间直接传输数据。

绕过了操作系统的页缓存，允许应用程序直接与磁盘设备进行数据传输，减少了数据在内存中的复制次数。

靠磁盘设备的驱动程序实现读写。

通常，对于磁盘，异步 I/O 只支持直接 I/O。

**具体流程**：

应用程序通过系统调用发起直接 I/O 请求，告诉操作系统需要从硬盘的特定位置读取数据到用户指定的内存区域。

操作系统告知硬盘控制器要读取的数据位置和长度等信息；同时操作系统会配置 DMA 控制器，将用户空间的目标内存地址以及数据传输的长度等参数设置好

最后dma将数据写到用户的指定内存区域。

**优点：**减少了拷贝次数，不会占用pageCache(不会影响热点数据)

**缺点：**

由于直接 I/O 绕过了 PageCache，无法享受内核的两点优化：io合并和预读

- 内核的 I/O 调度算法会缓存尽可能多的 I/O 请求在 PageCache 中，最后「**合并**」成一个更大的 I/O 请求再发给磁盘，这样做是为了减少磁盘的寻址操作；
- 内核也会「**预读**」后续的 I/O 请求放在 PageCache 中，一样是为了减少对磁盘的操作；

**异步io**

系统发起异步io读，直接返回；等到dma把数据拷贝到用户区，通知数据读取成功

**大文件传输**：一般就是异步io+直接io

**小文件传输**：零拷贝

Direct I/O 的效率并不一定比 Buffered I/O 低

- **大数据顺序读写场景**：在需要进行大量顺序读写的场景下，如数据库备份、大文件传输等，Direct I/O 由于减少了数据复制开销，通常可以获得更高的效率。因为在这种场景下，数据不会被频繁访问，页缓存的作用不大，反而增加了额外的开销。
- **小数据随机读写场景**：对于频繁的小数据随机读写操作，Buffered I/O 通常更具优势。因为操作系统的页缓存可以缓存这些小数据块，当再次访问时可以直接从缓存中获取，避免了磁盘的随机访问，从而提高了性能。而 Direct I/O 每次都需要直接访问磁盘，会导致大量的随机磁盘 I/O，效率较低

#### 顺序io

寻址快+预读(到内存)+io合并+	磁盘缓存(ssd有缓存芯片)

磁盘和固态：

机械硬盘：扇面，扇区，磁道；磁头寻找磁道和扇区耗时

固态：若干个闪存芯片+缓存+主控

#### **常见的IO模型**

结合38一起看

- **阻塞IO（BIO）：** 进程或线程在执行IO操作时被阻塞，直到IO操作完成才能继续执行。（指内核准备好数据之前）
- **非阻塞IO（NIO）：** 进程或线程在执行IO操作时不会被阻塞，立即返回，但需要轮询IO操作的状态，效率较低。
- **直接io：**不走pageCache，网卡/磁盘直接到用户区
- **异步IO（AIO）：** 进程或线程发起IO请求后，可以继续执行其他任务，IO操作完成后，系统通知。（异步io只支持直接io）
- **IO多路复用：** 通过select、poll、epoll等机制，一个进程或线程可以同时监听多个文件描述符，实现多个IO操作。

**IO分为两个阶段**：数据准备阶段和数据拷贝阶段；数据准备：硬盘到内核，数据拷贝：内核到应用

BIO需要等待数据准备和数据拷贝；

NIO会轮询数据是否准备完成，需要等待数据拷贝；

阻塞和非阻塞指是否等待数据从**磁盘拷贝到内核**这个过程；

但即使是非阻塞io，也需要while套个read，挨个找socket去读，有数据的返回，但while这个过程消耗资源，同时还有系统调用，如果没数据这个开销就是浪费的

所以产生了io多路复用，只找到/返回有数据的，去read；但要注意内核拷贝数据到应用这个过程仍要cpu完成，所以他们都是同步的

#### **IO多路复用**

一个服务器会与多个客户端建立连接，会有多个socket，所以一个进程需要同时能处理多个io

多路复用指的是多个请求复用一个进程，控制每个请求处理的耗时，如每个最多处理1ms， 1 秒内就可以处理上千个请求，类似cpu并发以也叫做时分多路复用。

把所有所有socket放到一个集合里，交给内核统一管理(epoll_ctl)，通过系统调用获知发生事件的socket(epoll_wait)，返回到用户区，去时分的处理(read)

具体的实现有select、poll（线性储存，两次遍历，两次拷贝）和epoll（内核红黑树，只传入新连接，传出发生事件的连接）

内核返回的判定又产生了两种触发方式，水平触发和边缘触发

水平触发只要还有事件未得到处理就让epoll_wait苏醒(有内容没读完就返回该socket)

边缘触发只有在事件发生那一时刻让epollwait苏醒一次(来了新的内容)，效率更高(苏醒涉及系统调用)

**补：**

基本socket是同步阻塞的，一时间只能处理一个客户端请求，如果与一个客户端的正在发生io或阻塞，其他客户端无法建立连接，所以需要多线程模型，一个线程去监听，多个线程去处理io，但这样会占用很多资源。

后来采用多进程/线程，多进程有上下文切换，创建销毁的开销；一个socket对应一个线程，但是这样频繁创建销毁，资源消耗大，难以达到c10k

**补**：返回有事件不一定是真可读，因为mac层，ip层，tcp层用的是一个数据，放到socket管理的发送/接收队列中，不同层只是调整了指针的指向来去除头部，所以可能后续检测时发现有错误，丢弃，如果用了阻塞io，调用 read/write 时就会发生程序阻塞，所以要搭配非阻塞 I/O，以便应对极少数的特殊情况。

**补：**每个连接都需要线程去处理业务（读写等），给每个连接都创建一个线程开销大，所以使用线程池，引入线程池就需要知道当前连接是否有数据可读，如果用socket的阻塞io，就没法去处理别的任务，如果用非阻塞（NIO），就需要cpu不断轮询，看有无事件发生，为了解决这个问题，用一个**监控线程**监控所有socket，连接上有数据，从线程池拿到一个线程，去处理

**补：**Reactor 模式则是对io多路复用做的封装

**补：**netty是对 Socket 的封装，非阻塞的事件驱动的网络应用框架

##### reactor

**Reactor结构**

 I/O 多路复用是面向过程的，后来基于面向对象的思想，对 I/O 多路复用作了一层封装，让使用者不用考虑底层网络 API 的细节，只需要关注应用代码的编写，就是reactor模式

 reactor对象通过select（io多路复用接口）监听事件，收到事件后通过dispatch分发，根据事件类型分发到acceptor（用于建立连接）或是handler（处理后续响应）

**41）reactor的三种模型**

- **单线程单Reactor**：一个线程处理所有的I/O事件，性能有限，无法充分利用多核cpu，业务耗时长会导致响应延迟。
- **多线程单Reactor**：主线程创建连接，监听事件，回复响应，创建子线程处理事件（一个reactor承担所有事件的监听和响应）
- **多线程多Reactor**：主线程main_reactor负责创建，接受新连接，监听到事件后将连接分配给子线程，子线程获取连接并继续监听，并创建一个handler用于处理连接的响应事件。

**Reactor和NIO的关系**、

**非阻塞io：**如果没有数据可读取或写入，IO操作不会阻塞当前线程或进程，而是立即返回一个错误或标记，告诉程序当前的IO操作无法立即完成。这样，程序可以继续执行其他任务，而不必等待IO操作完成。

处理连接上的事件需要线程，不希望频繁创建销毁，引入线程池，一般socket默认非阻塞io，这样没数据可读不确定是事办完了还是暂时等待，如果改为非阻塞需要轮询判断是否有数据过来，消耗cpu，所以希望能直接知道线程上是否有数据，方法就是多路复用，

所以非阻塞io+io多路复用+线程池 = reactor模式

reactor和handler组成，epoll监听多个socket，配合边缘触发，nio，一直读socket事件



补：网络高性能的原因：基于io多路复用实现的reactor模式，同时监听多个事件，根据事件类型分配给某个进程、线程

### Linux

##### Linux用过什么命令

cd，ls，cp，mv，rm，mkdir，pwd

ps，top，kill

ifconfig ping netstat

##### 排查问题常用指令

top看进程，netsat看网络，tail和grep看日志内容(直接看底部，和搜特定字符串)

##### 命令行输入命令后的执行过程

命令解析-语法检查-找到文件-创建子进程（一般父进程是终端）-子进程继承文件描述符，加载文件，执行-结果返回父进程或存到指定位置-子进程释放资源

解析命令：首先看是不是内置的，cd，ls这种

​	不是内置的要根据命令名，找可执行文件，加载到内存中（依次搜索path环境变量）；找不到报 command not found

找到后加载到内存，shell调用fork创建子进程执行；

执行结果显示到终端，子进程终止，资源释放

##### fork具体过程

本质上也是创建一个进程，所以先分配pcb

然后拷贝父进程资源到pcb

内存拷贝会涉及写时复制，父子共用，遇到写的再复制

复制文件描述符

创建main线程，初始化栈，程序计数器等

之后就成为一个独立的线程，可以执行任务，可以和父进程并发

补：fork父进程中调用，返回子进程id；调用失败返回负数；子进程fork返回0，从这个返回点开始执行；

