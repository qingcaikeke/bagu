| 对比维度     | RabbitMQ                                                     | Kafka                                                        | RocketMQ                                                     |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **功能特性** | **消息可靠性**：事务机制、确认机制、消息持久化 **消息顺序性**：需通过设置队列排他性等保证顺序消费，影响并发性能 **消息重试和死信队列**：可设置消息过期时间和重试次数，自动将重试失败消息发送到死信队列 | **消息可靠性**：多副本机制，生产者可配置不同确认级别 **消息顺序性**：分区内保证顺序，全局顺序需发至同一分区影响吞吐量 **消息重试和死信队列**：本身无内置，需开发者自行实现 | **消息可靠性**：支持同步刷盘和异步刷盘，主从复制机制 **消息顺序性**：支持全局顺序消息和分区顺序消息 **消息重试和死信队列**：支持消息重试，达最大重试次数后消息进入死信队列 |
| **性能**     | **吞吐量**：相对较低 **延迟**：较低                          | **吞吐量**：高 **延迟**：处理大量消息时相对较高，可调整参数降低 | **吞吐量**：高 **延迟**：较低                                |

![image-20250228125140413](C:\Users\16776\AppData\Roaming\Typora\typora-user-images\image-20250228125140413.png)


### MQ 

1.可以结合线程池消费 2.消息应答需要权衡吞吐量和安全性，可以自动应答和手动应答，手动应答又可以结合批量应答及窗口3.消息可以持久化到磁盘

**多线程异步和MQ异步**

**处理任务的维度：**多线程是进程内的概念，一个进程内多个线程并行处理任务，mq是通过把消息发到不同应用的不同进程来处理，**可靠性**不同，多线程数据存在内存里，程序崩溃数据会丢失，mq具备**分布式能力**，可以把任务发到不同节点储存消费

### 消息队列

##### 应用场景：

异步：正常串行执行，a系统调用b，c，d三个接口，执行时间是加和。如果a系统发条消息分别到3个队列，然后b，c，d之后可以任意时间执行，执行时间就是a的执行时间加上发送消息的时间。（侧重更快响应）

解耦：正常通过接口调用，如a系统调用b系统，但如果b坏了怎么办，a直接也不执行了吗？以及增加了一个c系统怎么办，修改a中的代码吗？通过消息队列可以使a不用管其他系统的变化，如下完单需要修改库存，及时当前库存系统除了问题，没办法写入，也能正常下单（侧重新系统接入要频繁改代码）

削峰：控制请求不超过处理能力

缺点：可用性降低（需要考虑mq挂掉）复杂度提高（需要考虑重复消费，消息丢失等问题）一致性（bc成功了，d失败了）

##### 可靠性

使用一个消息队列，其实就分为三大块：**生产者、中间件、消费者**，所以要保证消息就是保证三个环节都不能丢失数据。

生产阶段：队列收到消息要回复ack

消费阶段：一般收到消息就回offset，这样如果没处理完消费者就挂了就会出现消息丢失。

​		可以改成消费者接收消息+消息处理之后再回复ack(kfk中的手动提交偏移量)，但如果处理完，没来的及回offset，又会重复消费

储存阶段：副本+磁盘持久化，一个消息所在的队列挂了就使用replica

![img](https://mmbiz.qpic.cn/sz_mmbiz_png/J0g14CUwaZfW5jtMU7dzOUhL6avJSwsu2mjicVf2ZjCmpS93xWFUBk07GK7hqvIdMawwKV5YjXF69jnAPyuceKQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1&tp=webp)

##### 顺序

如mysql同步，即使队内消息有序，但多线程同时消费，有的执行快，如取出123，执行结果132

方案1：一个 partition，一个 consumer，内部单线程消费，但吞吐量较低

方案2：写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可

##### 重复消费(保证幂等)

一般结合业务手动处理，针对消费完成但没提交offset：生产者加个全局唯一id，消费到了先根据id去redis查一下(setnx)；或是直接根据数据库的唯一性约束。

也可能是生产者的问题：可能是一个controller被调用了两次，没有做**接口幂等性**；也可能是推送消息是mq响应较慢，触发生产者重试；

##### 高可用

集群+副本

#### 其他

##### **场景举例**：

订单十分钟未支付取消：用户下完单后存到数据库，数据库有个字段表示是否支付，然后把订单id放到延迟队列（10min后消费），在这期间，如果用户完成支付，把数据库的字段修改；等到了10min，进行消费，去数据库查订单状态，如果已支付，不用处理，未支付，将状态置为失效

##### 延时队列

**延时队列**：延时队列内部是有序的，希望元素在指定时间到了以后或之前取出和处理，如订单十分钟未付款取消，用户三天没登录发消息提醒。

延时队列可以通过死信队列+过期时间实现，也可以通过 Redis 的 zset或Quartz或kafka 的时间轮或Java 的DelayQueue实现

kfka如何实现：再开个topic，接收消息后等待延时，发到另一个topic（可能丢失）

##### **消息堆积?**

几千万条数据在MQ里积压了七八个小时

消费者消费速度与生产速度不匹配，看是否消费者出现异常，尽快恢复；

**紧急临时扩容：**新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量

写一个临时的分发数据的 consumer 程序，接收积压数据，直接均匀轮询写入临时建立好的 10 倍数量的 queue

临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。

然后还要查询这个时间内是否存在消息丢失，消息过期，因此可能需要手动查询，把丢失的消息补回来

增加消费者还是吞吐量低？可能都发到一个分区了，导致其他消费者没用上，

##### 广播

一个分区只能被一个消费者消费；事实上应该说一个分区在同一个消费者组内只能被一个消费者消费

但kafka本质上是发布订阅，生产者发布的消息会被广播到所有订阅了该主题的消费者组

所以只要一组一个消费者，然后都订阅一个topic，就能实现广播

##### 消息不丢失

消息队列作为一个中间件是不会丢消息（或者说这个它需要考虑的事），消息的从生产者获取到的消息一定会发送给消费者， 所以只需要考虑消费者这端，

可以使用队列或者单表来存储收到的消息。当消费者收到消息后，将消息存储起来，如果没有消费完，就将其状态标记为 “待重试”

后台开启一个线程或者定时任务，这个线程或任务会定期去检查存储消息的单表，扫描那些还没有被成功消费的消息

设置一个阈值，比如规定如果一条消息尝试消费超过 10 次都没有成功，就认为很可能是下游服务出现了问题。此时，系统会发出预警，并且对这条消息采取 “彻底断死” 的处理方式，即不再自动尝试消费这条消息，而是只允许人工介入查看和处理，以避免系统资源的浪费和可能出现的无限重试情况。

### KafKa

[Kafka 教程 | BIGDATA-TUTORIAL](https://dunwu.github.io/bigdata-tutorial/kafka/#📖-内容)

[一篇文章带你快速搞定Kafka术语](https://time.geekbang.org/column/article/99318)

[kafka为什么高性能](https://mp.weixin.qq.com/s/BHX-ElFT8ZE2alTk4lvt9A)

topic类似于数据库的表，一般一个业务一个topic？生产者只需要指定topic

**Record (Event)：**topic + partition + headers (offset) + key + value + timestamp

#### 生产者

概述：一个topic的消息会分为多个partition，不同partion分散在不同broker，同时每个分区有若干副本储存在别的broker，以保证某broker故障，其他副本仍能工作。副本复制由leader副本所在的broker负责，follower副本接收消息后向leader回复，ack参数确定几个follower复制成功后leader向生产者发送给确认。broker挂了会重新负载均衡，把partition分到新broker。

ProducerRecord：`Topic` + `Partition(非必填)` + `Key(非必填)` + `Value具体内容` 

计算分区：通过直接指定分区或通过key计算分区实现负载均衡

​		分区策略：轮询，随机，根据key算哈希，自定义(如根据源地址，目标地址等)

批次传输：同一分区的消息攒一批发送，大小达标或者是时间到了

等待响应：返回一个 `RecordMetaData` 对象，它包含了主题、分区、偏移量；失败返回一个错误，生产者收到后，可以进行重试

参数配置：key serializer，val serializer，compression type，batch.size，linger.ms，ack相关 ，重试相关，是否开启幂等性

补：配置后，Kafka 能自动帮你做消息的去重；但只能保证单分区的幂等性，只能实现单会话的幂等性（重启Producer进程，幂等性消失）；底层原理为broker多保存一些字段，能判断相同消息

#### 网易配置实践

背景：at-least-once-kafka-producer，记录storedKol user、搜索参数、接口名及返回数量落地到hdfs

```
broker集群地址，不需要包含所有broker，生产者会从给定的broker中获取集群的配置信息。
bootstrap.servers=ad-prod-01.kafka.yodao.cn:6666,ad-prod-02.kafka.yodao.cn:6666,ad-prod-03.kafka.yodao.cn:6666
```

```
k-v序列化的类
key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
```

```
生产者发送消息时使用的压缩类型
compression.type=gzip
```

```
批量发送消息。batch.size是每个批次的最大字节数，而linger.ms是生产者在发送批次之前等待的时间
batch.size=262144 (256kb)
linger.ms=10
```

```
Producer的缓冲区大小和缓冲区满时阻塞的最大时间。
不是凑够了一个batch就立即能发出去，batch要进入buffer，等待cpu调度，如果消息产生速度极快，而io能力跟不上或Kafka服务器处理速度不够，没能及时回复ack，就会导致缓冲区满，这个时候生产者就要阻塞xx毫秒，等待问题解决
buffer.memory=134217728 (/1024/1024 -> 128mb)
max.block.ms=60000
```

```
ack：需要有多少个分区副本收到消息，生产者才认为消息写入成功。
ack=1 (对应at-least-once)，leader将记录写到本地日志，不等待follower反馈，就确认成功
```

```
生产者等待请求响应的最大时间。如果在这个时间内没有收到响应，生产者会重试请求或失败。
request.timeout.ms=30000
```

```
生产者在遇到可恢复错误时的重试次数和每次重试之间的等待时间。
retries=3
retry.backoff.ms=500
```

```
kourier消费者
group.id=witake-es-test——消费者组标识
auto.offset.reset=latest——新消费者加入或找不到已提交的偏移量，从分区的最新消息开始读
enable.auto.commit=false——手动提交偏移量，一般处理之后提交，保证不丢失
max.poll.records=1000——一次最多poll 1000条消息
```



#### 消费者

消费者组：一个群组里的 Consumer 订阅同一个 Topic；一个 Partition 只能隶属于组中的一个 Consumer；一个Consumer可以负责多个Partition。

一般来说消费者组订阅的是topic，Kafka自动将主题下的分区分配给消费者。当消费者数量或者分区数量发生变化时，也是Kafka 自动地重新分配分区，以确保每个消费者处理的工作量相对均衡。只有特殊情况才需要手动指定分区。

消费流程：pull模式，不会超出消费能力。轮询请求消息(Offset)，不是立即返回结果，而是等待累计一定量数据或超过指定时间 ，即:`customer.poll(time)` 

poll除了拉消息外，也有向群组协调器的 Broker 发送心跳的作用，以证明自己存活。

偏移量提交：kafka第一个消费者启动，自动创建一个**`_consumer_offsets` 主题**，消费者向该主题发送消息，消息包含每个分区的偏移量

#### Kafka服务器

ZooKeeper：每个broker启动时，创建临时节点把自己的id注册到zk。Kafka 组件订阅 Zookeeper 的 `/broker/ids` 路径，当有 Broker 加入集群或退出集群时（zk节点状态发生变化），zk会通知Kafka客户端。会话结束时，zk删除临时节点

副本：副本分区和主分区通过偏移量同步，副本告诉主分区自己已复制到的偏移量位置，主分区根据这个消息确定哪些内容发送给副本分区

##### 高可用

- **持久化**：Kafka 所有的消息都存储在磁盘，天然支持持久化。
- **副本机制**：Kafka 的 Broker 集群支持副本机制，可以通过冗余，来保证其整体的可用性。
- **选举 Leader**：Kafka 基于 ZooKeeper 支持选举 Leader，实现了故障转移能力。

##### 可靠性

储存阶段(broker)：磁盘储存 + 副本机制 + 不完全的选主 + 最少同步副本 —— 禁止不完全选主，副本数大于等于3，消息至少写到两个副本才是已提交

生产阶段(Producer)：同步/异步发送 + ACK + 重试 ——使用带回调的send，ack=all，retries设置一个较大的值

消费阶段(Consumer)：——手动提交位移，确保消费完成再提交

补：当设置acks参数为all时，生产者会等待至少min.insync.replicas（即最小同步副本数）个副本成功复制消息后，主副本会向生产者发送确认消息。

##### 高性能

[kafka为什么高性能](https://mp.weixin.qq.com/s/BHX-ElFT8ZE2alTk4lvt9A)

分区处理 + 批处理 + 顺序磁盘访问 + 零拷贝 + 消息压缩

- **分区、分段、索引**：基于分区机制提供并发处理能力。分段、索引提升了数据读写的查询效率。
- **批量发送**：收发都是批量的，一批消息属于同一个partition，Broker收到消息后也不会把批量消息拆分成单条再落盘，而是直接一批同步给其他副本，消费者拉也是直接拉一批。要么大小足够构成一批，要么时间到达构成一批
- **顺序读写**：机械硬盘寻址需要移动磁头，这个机械运动很耗时。所以Broke消息落盘时，首先为每个 Partition 创建一个文件，然后追加写，写满了建个新文件继续写
- **零拷贝**：利用零拷贝技术，正常即使命中了PageCache也要先内核到用户，再用户到内核(Socket buffer)，再到网卡缓存。而零拷贝直接PageCache缓存映射到socket，然后DMA直接内存拷贝到网卡，不用CPU参与
- **消息压缩**：可以选择是否开启。生产者攒一批消息才发送，发送之前会压缩，Broker会解压header做一些校验，但不解压消息体，因为压缩和解压会占用cpu

#### 其他

分区数目太多会怎么样（单机上）：

顺序写入受限，因为要不停切换写入位置；每个分区都需要一定缓存空间，可能导致空间不足

那为什么不设计成一个分区：

为了水平扩展，存更多数据；生产者可以并发的写；消费者可以并发的读

实际上是消费的时候，读从一个大分区和多个分区读，消费者呢？

100个分区只读一个分区

读的时候，fread，传一个文件句柄，一个偏移量，一个返回的数据量；实际上操作系统并不是指定多少就读多少

里面有个预读的概念，保证下次读会快

所以如果一个分区，你读的都是一个文件，预读全命中，对磁盘的压力就小了

从业务选型看，什么场景适合把所有分区放到一个文件里（rmq），什么场景适合把分区分开，每个分区单独一个文件（kfk）

前者实际上是rmq的方案，后者是kfk的方案

所以对使用方来说，rmq的使用方能更快的接收到数据，消费快，落盘快

而对生产者来说，kfk可以更快的

哪种写更优，哪种读更优



分区文件的布局

- **Kafka**：以 Topic 和 Partition 为主，每个分区对应一个物理文件夹。文件在分区级别实现顺序写，其布局为`Topic/partition`。
- **RocketMQ**：所有主题的消息顺序写入一个物理文件（commitlog），然后基于 commitlog 文件构建消费队列文件（ConsumeQueue），消费队列按`/topic/{queue}`组织。

消息写入机制

- **Kafka**：每个分区有单独的文件夹，消息写入时是分区级别的顺序写。当一个 Kafka 集群有大量主题和分区时，高并发写入会导致其 I/O 操作零散，相当于随机 I/O。

​		在分区数量不多的情况下，其分区级别的顺序写可以重复发挥 CPU 的多核优势

- **RocketMQ**：追求**极致的顺序写**，所有消息不分主题一律顺序写入 commitlog 文件，topic 和分区数量的增加不会影响写入顺序，
- 
- rmq延时低，而kfk在处理大量消息的时候延时高。

### kourier源码

```
    private volatile boolean keepConsume = true;    
    @PreDestroy
    public void close() {
        keepConsume = false;
        log.info("set keep consume to {}", keepConsume);
        // 等执行线程关闭后再关闭kafka consumer，防止重复消费
        kafkaConsumerRunSingleThreadPool.shutdown();
        CloseableUtils.closeQuietly(kafkaConsumer);
        log.info("kafka consumer closed.");
    }
    private void consume() {
    	while (keepConsume) {}
    }    
```

### RabbitMq

[消息队列介绍 | OddFar's Notes](https://note.oddfar.com/pages/2c91a1/#四大核心概念)

**核心概念**：生产者，交换机，队列，消费者，消息可靠性（确认机制，持久化，消息过期机制，死信队列），延迟队列，顺序消费，消费幂等性

**创建消息队列的参数**：消息队列名称，是否持久化，是否**只允许当前这个创建消息队列**的连接操作消息队列，没有人用队列后，是否要删除队列 ，队列参数（如过期时间等）

**五种工作模式**：简单模式（单生产单消费）工作队列模式（多消费绑定到同一队列，之后轮询分发(一半一半)或公平分发(能者多劳））

Fanout/Direct/Routing都是交换机的类型，把队列绑到交换机上

发布订阅（Fanout 从这个开始加交换机，消息会广播到所有绑定交换机的队列上）

路由模式（Direct/Routing，队列注册的时候有个binding key ，根据消息的binding key发送到对应的队列去）

主题模式（Topics，点分加通配符，实现更灵活的路由匹配）

![image-20250220202206489](C:\Users\16776\AppData\Roaming\Typora\typora-user-images\image-20250220202206489.png)

**消息过期机制**

允许你为消息设置一个过期时间，在此时间后，如果消息仍然未被消费者消费，将会自动从队列中删除。

**消息确认机制**（消费成功、消费失败、拒绝）

自动确认：一收到消息就回复ack，手动确认：可以指定某条消息回复消费结果（成功，失败，拒绝）

指定是否确认某条消息（id）+是否批量确认+指定拒绝多一个参数（是否重新放回消息队列）

##### **死信队列**

和正常队列一样，也具有储存消息的功能，不过储存的是失败的消息；

为了保证消息的可靠性，比如每条消息都成功消费，需要提供一个容措机制，即：失败的消息怎么处理？

通过给正常队列配置死信队列和死信交换机，将死信存到死信队列，然后再起一个消费者消费死信内容

这个转移过程是由消息队列的底层机制实现的，通常会在后台自动完成，无需人工干预。

死信**来源**：消息达到TTL，队列长度已满，消息被拒绝（给队列配置TTL，到时间立刻丢弃或进死信队列，给消息配置要等到消费者查看才能发现），消息处理失败

死信交换机，绑定正常队列与死信队列

**消息基于什么传输**

由于TCP连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ使用信道的方式来传输数据。信道是建立在真实的TCP连接内的虚拟连接，且每条TCP连接上的信道数量没有限制

```java
创建交换机，声明类型
创建队列
队列绑定交换机（队列名，交换机名，bindingKey）
	即交换机，收到xx消息，根据消息key发送到 绑定该交换机且满足条件的队列
	channel.queueBind(queueName, EXCHANGE_NAME, "error");
	channel.queueBind(queueName, EXCHANGE_NAME, "*.*.rabbit");
消息发到交换机，发送时指明交换机name和消息的key
	channel.basicPublish(EXCHANGE_NAME, bindingKey, null, message.getBytes("UTF-8"));
```

