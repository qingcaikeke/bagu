学习重点：锁，索引，事务，sql优化

**数据库的三大范式**

1.属性不可再分2.非主键列完全依赖于主键3.非主键列之间没有传递依赖关系（一个表的每一列都只能依赖于主键，而不能依赖于其他非主键列。）

非主键列 A 依赖于非主键列 B，同时非主键列 B 依赖于主键，那么这种情况就被称为传递依赖

如果 A → B（A 函数决定 B），同时 B → C（B 函数决定 C），那么我们称 C 对于 A 具有传递依赖

如：学号姓名班级班主任 应该拆成两个表：学号姓名班级+班级班主任

**结构化与非结构化**

结构化与非结构化（没有严格约束，形式自由，可以是键值型，文档型，图格式）
关联与非关联（表之间没有关联（外键），要么通过业务逻辑实现，要 么通过数据耦合）
查询方式（不是sql语法，形式各样）

**关系型数据库和非关系型数据库的优缺点对比，应用场景**

关系型：强调数据一致性，支持acid，支持复杂查询，适合数据结构稳定，不常变化可扩展性有限，金融系统

​				关系型数据库因为表之间存在关联关系，如果做水平扩展会给数据查询带来很多麻烦

非关系型：灵活易于水平扩展，可以处理非结构化、半结构化数据，缺乏标准化，大数据，高并发高扩展

**ORM框架，采用ORM框架的优缺点**

使用面向对象的方式操作数据库，不必关心底层sql操作。表中每一行数据看成一个实例对象，建立person表到person类的映射对象

**一条SQL语句的执行过程，SELECT是如何执行的，UPDATE是如何执行的**（连接  - >服务器（解析，（预处理）优化，执行） -> 引擎）

mysql架构分两层（server层负责建立连接，分析执行sql，储存引擎层负责数据的储存和提取）

连接器---查询缓存---解析器---预处理器---优化器---执行器

连接器：三次握手建立连接，校验用户名密码，读取用户权限，后续所有操作基于此时权限

查询缓存：把语句当作key结果当做value缓存起来，缓存命中率低，因为只要一个表进行了更新操作，缓存就会被删除，8.0之后删除了查询缓存

解析器：解析sql语句，进行词法分析（标识关键字和非关键字）和语法分析（构建sql语法树，方便后续获取sql类型，表名，字段名，where条件等）

预处理器：检查表或字段是否存在，将*扩展为所有列

优化器：确定执行方案，确定多个索引中使用哪个索引，explain是在优化器这一阶段

执行器：执行sql语句，与储存引擎交互（使用索引/全表扫描/索引下推）

#### bufferPool

数据存在磁盘里，每次都从磁盘取，性能差，所以加了个内存缓存，也就是bufferPool

大小以 ·页· 来划分，以页作为磁盘和内存交换的基本单位。(一页包含多行记录)

bufferPoll中内容包括：索引页，数据页，undo页(注意不是redo)，锁信息

为了方便管理，每个页创建一个控制块，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等。

同时把页分为：空闲页，干净页，脏页。

配合改进的LRU算法提高缓存命中率：把链表分为 old 和 young 两个区域，加入缓冲池的页，优先插入 old 区域；页被访问时，才进入 young 区域，目的是为了解决预读失效的问题。

当页被访问且 old 区停留时间超过 `innodb_old_blocks_time` 阈值（默认为1秒），才把页插入到 young 区域，否则还是插入到 old 区域，目的是为了解决批量数据访问，大量热数据淘汰的问题。

脏页刷新：

- 当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；
- Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；
- MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘；
- MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；

补：redo log不在这里(bufferPool)，另外的空间，定期刷盘，undo页的变化也会存到redo log

**整个索引查询的过程是怎样的？**

每一个节点是一个数据页，一页中有多条数据，根节点通过二分查找定位含查询值的页，然后向下查，继续定位含查询值的页，找到叶节点，最终找到查询记录

**什么是索引，为什么要用索引，索引的优缺点**+

索引就是数据的目录，是**一种排好序的数据结构**，用于快速定位数据库中特定行

为什么快：**索引提供有序的数据访问路径**，避免对整个表的遍历，同时可以加速排序、多表连接等操作

为什么要用：1.**提高查询速度**（通过索引定位所需的数据块）2.加速排序聚合（计算总和，平均数）等操作3.可以保证每行数据**唯一性**4.优化多表连接速度

(为什么排序快：索引本身有序；多表连接快：找到要连接的列的索引，分别回表就能得到两个表中对应行的数据)

**缺点：**占用额外的储存空间，创建和维护索引需要耗时，会降低写操作（增删改）的效率

补：储存引擎：如何储存数据，如何为数据建立索引，如何更新、查询数据

![image-20250215155130928](C:\Users\16776\AppData\Roaming\Typora\typora-user-images\image-20250215155130928.png)

### 索引相关

**索引的应用场景**

字段有唯一性限制（商品编码），经常用于where条件查询的字段（若索引不是一个字段，可建立联合索引），经常用group by/order by的字段（因为索引是排好序的）

​		简而言之需要经常查，快速查的（等值查询，范围查询，排序，多表连接，聚合）

补：覆盖查询：索引包含要查询的所有列，不需要回表查整行的信息，减少io次数

不适用：不需要快速定位（where order group）

字段中存在大量重复数据（性别）（优化器判断某个值出现的百分比很高，就不用索引）

数据很少的字段，经常更新的字段（用户余额）

**索引的实现方式/索引采用的数据结构，它们之间的区别**

哈希索引：等值查询很快，但不适合顺序查询和范围查询（需要根据索引分别计算其位置），可能发生哈希碰撞，不同val计算出的key一样，导致触发全表扫描

红黑树：平衡二叉树，与AVL的区别在于不追求严格的平衡，而是大致的平衡，查的速度下降，增删速度大大提高

b树：多路平衡查找树，所有节点既放索引又放整行数据；随机访问多，更新少，用b树；更新多，范围查找多用b+树

b+树：叶节点存放数据和索引，非叶节点只存放索引，叶节点之间双向连接，所有索引都会在叶节点出现

io次数更少（读一个节点相当于一次io），速度更稳定（所有数据都在叶节点），更适合范围查询（叶节点数据按顺序存放）

​	补：磁盘 I/O 操作是以页（Page）为单位进行。每次从磁盘读取数据时，会将一个页的数据加载到内存中。页的大小是固定的，非叶节点只存放索引不存具体数据，就可以存更多索引，从而降低树的高度，进而减少io次数

全文索引：在文本（varchar，text）列上的索引，用于在文本数据上高效搜索

优点：内存页能存放更多的key，数据存放更紧密，缓存命中率高

**总结：为什么MySQL喜欢b+树**（更矮胖，更多冗余节点，范围查询）

从查的角度来看：使用二分的结构定位数据，平衡保证查询不会退化成链表，又因为树的高度决定磁盘io次数，通过多叉树降低树的高度

同时b+树非叶节点不存放数据，可以存放更多索引，让结构更矮胖，io次数更少		-----   	同时叶节点双向链表连起来，便于范围查找

从增删的角度来看：b+树有很多冗余节点，插入删除效率更高，不会发生复杂的树的结构变化

存储千万级的数据只需要 3-4 层高度就可以满足，千万级的表查询目标数据最多需要 3-4 次磁盘 I/O。

**时间复杂度**：一个节点最多有n个子节点，节点总数为m，(1+n+n^2+...n^k = m  -> k = log(n)(m)，所以复杂度lognm)

**索引的类型、索引的种类**

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**。
- 按「物理存储」分类：**主键索引、二级索引**
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**。
- 按「字段个数」分类：**单列索引、联合索引**。

主键索引：一张表只能有一个，唯一且非空

二级索引：包括唯一索引，普通索引等，二级索引叶节点储存的数据是主键，即通过二级索引定位主键位置

唯一索引：不可重复，但是可以为null，一张表可以有多个，

普通索引：可重复，可空，可多个

前缀索引：只取字符串前几个字符建立索引，比普通索引占用空间更小

联合索引：多列值组成一个索引，专门用于组合搜索

补：**联合索引的最左前缀匹配原则**，mysql会根据联合索引中的字段顺序，从左到右的去匹配，所以一般将区分度更高的放在最左面，可以过滤更多数据。同时，如联合索引（a,b,c）中是先按a排序，a相同再按b排序，所以a是全局有序的，b和c全局无序，局部有序，而利用索引的前提是索引key是有序的，所以where a>1 and b=2，只有a字段使用了联合索引进行查询，b字段没有用联合索引，而是通过回表，mysql5.6之后引入**索引下推优化**，和联合索引一起使用，先对索引中包含的字段判断，过滤不符合条件的，减少回表次数

​	即：建立联合索引有顺序(创建（a,b,c）联合索引，和（b,c,a）联合索引是完全不同的，是不容的储存内容)

​	使用联合索引同样也有顺序。有（a,b,c）联合索引

**补：索引下推**：减少使用二级索引时的回表次数，不使用索引下推时，首先定位满足条件的第一条二级索引记录，然后回表，将完整的记录返回给server层，server判断是否符合下一个条件，符合的话返回给客户端。而索引下推查到二级索引后，引擎判断是否符合下一个条件，不符合跳过，符合执行回表操作，将完整的记录返回给server层（优化器判断是否使用索引下推，具体执行是引擎实现）

索引下推不一定要联合索引，索引下推具体指的是在储存引擎扫描索引的时候，对额外字段进行判断，将不满足条件的记录提前过滤调(可能通过联合索引，也可能通过回表看具体数据)。否则要全召回，然后服务器层进一步判断

**聚簇索引和非聚簇索引**

索引和数据一起放：查询快，排序和范围查找快（innoDB中的主键）缺点：更新代价大，

索引和数据分开放，叶节点可以是指向数据的指针，也可以是主键。优点：更新代价小	缺点：可能需要二次查询

**什么是回表查询，非聚簇索引一定要回表查询吗**

回表：按二级索引查找某商品，需要先检索二级索引的b+树，找到对应的叶节点，获取主键值，再通过主键索引的b+树，找到叶节点，获取整行数据

不一定：如果查询的数据可以直接在**二级索引的叶节点**里查询到就不用（索引包含了查询中所有需要的列即**覆盖索引**）

**索引什么时候会失效**

左或者左右模糊匹配：like %林%不行，%林不行，林%可以，因为索引b+树是靠索引值有序排列储存的

在查询条件中对索引列做了**计算、函数、类型转换**等select a from table where length(b) = 3；索引列是字符串，条件是数字，会发生隐式转换，等于用了函数

联合索引没有遵循最左匹配原则，先根据第一个字段排序，后面的字段只是局部有序的

​	abc联合索引：where a = xxx，用了；where a = xxx and b = xxx，用了；where b = xxx，没用；

​	where a = xxx and c = xxx，用了a部分；

or前后存在不是索引的列，where a=1 or b=1

in使用不当，得到的**结果集过大**，引擎判断使用全表扫描更好

#### 违反最左匹配

a,b,c联合索引：

1.where a =x and c=y

2.where b = x and c= y

where

**如何查询是否使用索引**

可以通过explain命令分析sql的执行计划，看是否命中索引了，explain不会真的去执行语句，而是通过优化器进行分析，找出最优查询方案

**索引是越多越好吗**：多了浪费空间，写入频繁的场景下维护消耗的资源多

**建立索引的注意事项：**（有100个字段，需要建立索引，怎么建）

1.选频繁查的建索引 2.被用于条件查询的，要排序的，频繁用于连接的 3.频繁更新的不要建索引 4.索引不能太多 5.尽量用联合索引 （where，order，group）

### 慢sql优化

**Mysql中sql语句执行太慢，是什么原因，怎么解决，用什么命令查看（如何进行sql调优）**

通过**慢查询日志**找到慢sql，通过explain去分析sql语句，观察生成的执行计划，看是否因为没建立索引，索引失

效，也可以通过建立联合索引进行覆盖索引优化，减少回表   

**慢查询日志怎么开：**配置文件修改配置项

type查询类型；possible_keys可能用的索引；key 实际用的索引 

**expain的type字段**：ALL<index<range<ref

**all：**全表扫描，

**index**：用了索引，但是把索引从头到尾都扫描了一遍，省略了排序的过程（索引有序），一般会出现在覆盖索引，扫描索引树比全表开销小很多，例：SELECT `birth_year`,COUNT(*) FROM `user` GROUP BY `birth_year，例：查全表数据总条数

**range**：取了一定范围的索引，一般where条件，

**ref：**非唯一索引**等值查询**（可能查到多行），eq_ref则对应唯一索引，只找到一行

一般来说 all和index需要优化

**其他**：1.数据库太大，需要分库分表 2.数据类型有无优化空间，字段长度精度是否合理 3.数据库参数优化，如连接数 4.硬件方面

**mysql，sql查询语句慢了怎么优化，sql插入语句慢了怎么优化**

查询：使用explain查询执行情况，是否使用索引，可以加索引，联合索引，（数据量太大，分库分表）
避免使用*，避免%，避免索引失效，使用limt限制结果集大小，避免查询大量数据

插入：1.批量插入，将多个插入语句合并成一个，减少数据库交互次数。2.关闭自动提交，等所有插入完成后手动提交

#### **分页查询优化**+

1.SELECT * FROM 表名称 LIMIT M,N（从m到m+n-1）（或者limit N offset M）：全表扫描，从m的位置拿出n条数据，查询结果不稳定（213，231）,最好使用order by。查询时间与起始位置成正比，所以，优化1：**使用order by，同时给排序字段加索引**

优化：（1）使用覆盖索引（2）如果还是要查所有列，可以使用**子查询提高分页效率**，先把id查出来

```
SELECT id, name, gender, score
FROM students
ORDER BY score DESC
LIMIT pageSize OFFSET pageSize * (pageIndex - 1);

例如：type = 8有很多数据，要分页展示，可以先查出type等于8的所有数据，找到第1000条（新一页第一个）的id，因为id是索引
select * from orders_history where type=8 and 
id>=(select id from orders_history where type=8 limit 100000,1) 
limit 100;
```

当limit起点较高时，可**先用过滤条件进行过滤**。

如 `select a,b,c from t1 limit 10000,20`; 优化为 `select a,b,c from t1 where id>10000 limit 20`

### 其他

#### 自增id

好处：顺序插入，避免随机io和页分裂。保证唯一，天然有序，可以直接当主键（主键索引一定唯一且非空）

乱序id：影响插入性能，导致随机io；同时还可能导致页分裂，页分裂会将一个满的索引页分裂成两个页，需要进行额外的 I/O 操作和数据移动(一次性插好几个)，增加了插入的开销。

#### 外键

外键是：指向另一个表的主键的字段或字段组合。通过外键，可以确保一个表中的数据与另一个表中的数据存在关联关系。order表里有一列客户id

外键可以加索引，正常索引优点都有，还可以加速join



**.frm文件和.idb文件**

idb指innoDB，用于存储表的数据和索引

.frm文件用于存储表的结构定义，包括列名、数据类型等

#### **JOIN和UNION**

`JOIN` 用于合并行，基于相关列将两个表格连接在一起，操作的对象是表格，不会去重，比方说查询结果中**连接条件**这一列会出现两次

`UNION` （组合查询）用于合并结果集，即将两个或多个查询的结果组合在一起，操作的对象是select语句的结果集，默认去重（union all不去重，更快一点，union会触发先排序再去重）

**左连接、右连接和内连接的区别?**（Left Join，Right Join，Inner Join）

内连接返回左右表中都匹配的行。如果没有匹配的行，就不会显示在结果中（不写默认inner）

左连接返回左表中所有的行，以及右表中与左表中相匹配的行 

右连接返回右表中所有的行，以及左表中与右表中相匹配的行。如果左表中没有匹配的行，将返回 NULL 值（右表中的数据为主，即使左表中不存在匹配数据也会把右表中所有数据返回）

（select * from Students s right join  Class c  on s.ClassId=c.ClassId）没有对应的学生在三班

会出现一行 NULL NULL NULL 3 三班 王老师

### **事务**

转帐前开启事务，转账成功修改永久生效，中途发生错误回滚到修改之前的状态

A（atomicity）原子性:一个事务必须被视为不可分割的最小单元，事务中所有操作要么全成功，要么全部失败回滚，不可能只执行一部分

C(consistency)一致性：事务操作前后，数据满足完整性约束，从一个一致性状态到另一个一致性状态

I(Isoliation)隔离性：并发事务修改相同的数据，每个事务有一个完整的数据空间，不会相互干扰，

D(Durablity)持久性：事务提交，修改是持久的，系统崩溃修改的数据也不会丢失

**事务怎么实现**

由搜索引擎实现，InnoDB支持事务，MyISAM不支持 

- 持久性是通过 redo log （重做日志）来保证的；
- 原子性是通过 undo log（回滚日志） 来保证的；
- 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；

#### **并发事务引发的问题**

等于并发修改同一条数据会发生什么？

脏读（第二个事务读到了第一个事务未提交的数据，然后第一个事务回滚），

不可重复读（a事务读取数据，b事务修改数据并提交，a事务再次读取发现两次读取的结果不一样），

幻读（在一个事务内多次查询某个符合查询条件的**记录数量**，前后两次查询到的记录数量不一样的情况，a查100以上的数据条数，发现有五条，b加了一条并提交，a再次查询发现变成六条）

严重性排序：脏读》不可重复读》幻读

补：怎么加行锁：select for update		

**事务的隔离级别**(读未提交，读提交，可重复读，串行化)

隔离级别越高，性能效率越低

隔离级别：读未提交（事务还没提交，所作的变更就能被看到）
	《读提交（提交了才能看到）

​	《可重复读（事务执行过程看到的数据一直跟事务开启时看到的数据相同，innodb默认级别）

​	《 串行化（serializable序列的）（加**读写锁**，发生读写冲突，一个事务完成才能开始下一个事务）

 InnoDB 引擎的默认隔离级别是可重复读，但是能很大程度解决幻读，针对快照读(普通select)通过**MVCC**解决（事务执行中看到的数据一直和开始时的数据是一样的，因为只创建了一份快照，即使插入了一条数据，也看不见)，针对当前读(select for update)通过**临键锁**

「读提交」和「可重复读」隔离级别的事务是通过**Read View**实现。区别在于生成快照的时机不同

「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。

**为什么默认的隔离级别是可重复读**

满足常见业务场景的并发需求，没有脏读和不可重复读；

如果要完全解决幻读需要加锁，开销大，效率低，还有死锁风险

通过读取数据的历史版本来实现并发访问，避免锁竞争，并发性能也高，因为多事务可以同时读一个数据，不会阻塞

#### **MVCC实现原理？**

Read View 在 MVCC 里如何工作的？

事务开始生成一个快照，查数据的时候看两个隐藏字段，事务编号和指针

Read View有四个字段：1.创建该快照的事务id ——2.创建快照时的活跃未提交的事务id的列表—— 3 .创建时活跃事务的最小id ——4.应分配给下一个事务的id（creator_trx_id,m_ids,min_trx_id,max_trx_id）

聚簇索引记录中存在两个隐藏列，trx_id（修改该记录的事务id）和roll_pointer（每次对某条聚簇索引记录进行改动时，都会**把旧版本的记录写入到 undo 日志**中，然后这个隐藏列是个指针，指向这条旧版本记录），集合readview快照和undoLog版本链，就能知道可见的数据版本应该是什么样的

通过「事务的 Read View 里的字段」和「记录中的两个隐藏列」的比对，来控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。

优点：无锁实现事务的可重复读隔离级别，提升并发性能，降低死锁风险

缺点：占用空间（存旧数据）；数据库额外开销，管理事务id，因为readView要用；数据的两个隐藏列要额外维护；

#### **怎么解决幻读的？**

针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的（readview）,即使中途有其他事务插入了一条数据，是查询不出来这条数据的。（select where id>2 ,事务2：insert id =5）

针对**当前读**（select ... for update 等语句），是通过**临键锁方式解决了幻读**，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入。

当前读每次执行前都会获取最新数据，假设无锁，(select id>2 for update，insert id=5，再次执行selct id>2 for update。发生幻读)

可重复读级别不能完全避免幻读，select id=5 空 不加锁，insert，再select id=5 发现有，幻读了

反证好像是只要锁范围的数据不能被其他事务修改，就没幻读，所以只要加上锁，这个范围的数据就不会变化幻读就解决了

 update、insert、delete都是当前读(相当于默认前面加了select for updte)，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。比方说要update某一行数据(或一个范围)，但有未完成的事务持有该行数据的的排他锁，这个update操作就会被阻塞，为了提高锁的效率，还会加意向锁锁，表示在更细粒度的层面加锁

补：t1事务a：update id=25。t2事务b：update id =26 。t3事务c：insert id =25。t4事务d：insert id =26 

发生死锁，两个`(20, 30)`的临键锁可以共存，插入25生成一个插入意向锁，但这时事务b已经加上了一个临键锁，这两个锁不能共存，a的插入意向锁需要等待b的临键锁，而b的意向锁需要等待a的临键锁，这就发生死锁

**为什么没完全解决**

快照读没加锁，和当前读混合就有幻读了

有个表，有id1，3

事务1：select id=2 》0条数据

事务2：插id等于2，提交

事务1：update id =2，成功，虽然看不见这条数据，但这时候能更新

事务1：select id = 2》一条数据，因为上一句update会把id=2这条数据的隐藏列中的事务id置为事务1的id，然后这个数据就对事务1可见了

场景2：

- T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id > 100 得到了 3 条记录。
- T2 时刻：事务 B 往插入一个 id= 200 的记录并提交；
- T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id > 100 for update 就会得到 4 条记录，此时也发生了幻读现象。

为什么能读到，因为当前读获取的是最新的数据，而非使用mvcc的快照机制；

总之：当前读会读取到已经提交的最新数据

他能知道哪些事务是活跃的，未提交的(数据库系统会维护一个事务列表，记录活跃的)，然后这些数据用旧版本，其他都用最新的

### 锁

**MySQL数据库有哪些锁，或者说按粒度分类**（全局锁，表锁，行锁）

全局锁：整个数据库只读状态，主要用于全库逻辑备份，加上后全库只读，

例：1.备份了用户表 2.用户下单，用户扣钱，商品减1

3.备份后用户没扣钱，但是商品减1了 -----只读不方便，在备份数据库之前先开启事务，会先创建 Read View，这样备份一直用快照，但是能更新数据库

表级锁：针对**非索引字段**加锁

行级锁：针对**索引字段**加锁，只针对当前操作的行记录进行加锁

**MySQL的表级锁有哪些？**

**元数据锁：**MDL，防止对表进行crud时，有别的线程更改表结构

**意向锁：**快速判断表里是否有记录被加锁。

不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁，读锁）和排他锁（Exclusive Lock，X 锁，写锁）这两类

**MySQL的行级锁有哪些？**

记录锁（Record Lock）：锁定某行数据，防止其他事务对同一行数据的并发修改。

间隙锁（Gap Lock）：锁定一个范围的数据，防止其他事务在该范围内插入新的数据（前开后开）

临键锁（next-key lock）：记录锁和间隙锁的结合，锁定一个范围，并且锁定记录本身，用于解决幻读（前开后闭，和版本有关）

例：表中数据1，5，10，15，20更新id=1会加记录锁，更新id等于2加间隙锁（1，5）（插入3不行，改5行），

todo 为什么能避免幻读：因为这个插入事务，导致别的事务中两次查某范围的数据个数不同，在可重复读的基础上

只要保证前后两次查询 id = 2 的结果集相同，就能避免幻读的问题了，所以即使 id =5 被删除，也不会有什么影响-------本质上都是临键锁退化

select id>15(加临键锁 (15,20] 临键锁(20,+∞)) -----select id≥15(加记录锁15，加临键锁 (15,20]，临键锁(20,+∞)) 

更新id>10且≤15加临键锁（插入12失败，更新15失败）

补：update 语句中 where 条件没有索引列，会触发全表扫描

**补：行锁的两阶段协议：**不是在事务开始时加上所有锁，而是在语句执行的时候才加上锁，但是所有锁都是等到事务结束才释放，因此为了提高并发性能，要把容易发生冲突的锁放到后面（1.顾客扣钱2.影院加钱3.生成订单）->（正确顺序312/132）

#### 死锁排查

可以开启死锁检测，看错误日志，看**SHOW ENGINE INNODB STATUS**引擎状态信息

或是用一些监控工具

### **MySQL日志**

undo log（回滚日志）：引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。

记录了原始数据，roll_pointer 指针和一个 trx_id 事务id，roll_pointer 指针将undo log串成版本链

redo log（重做日志）：引擎层生成的日志，实现了事务中的**持久性**，主要用于持久化，掉电等故障恢复；

​	循环写，空间固定，会覆盖。记录的是具体内容，如某数据页某偏移量具体改成什么字节。是储存引擎层的

​	**先写日志再写数据页**的方式称为预写式日志（Write-Ahead Logging，WAL），类似把log当成一个buffer，比直接改效率高

bin log （归档日志）：Server 层生成的日志，主要用于**数据备份和主从复制**；即主从复制场景下，记录master的操作；二进制格式储存对数据库的更改操作。是服务层的

记录的是类似被执行的sql语句，是追加写，不会覆盖之前的内容，随时间推移，文件越来越大

为啥掉电回复用redo：效率高，不用重新执行一次sql。有事务中间状态等信息

**提交事务的一整个过程，每个日志都是怎么工作的？**

1.看数据在不在buffer pool中，在的话直接加载，不在从磁盘读数据到buffer pool，返回给执行器

2.执行器看执行前后数据一不一样，不一样开启事务，首先生成undo log记录旧值，也写入buffer pool

3.更新记录，标记为脏页，把对这个页的修改以redo log的形式记录下来，事务提交只需要先将redo log持久化到磁盘，不用等脏页数据提交到磁盘；数据持久化到磁盘要先找到写入位置，是随机写，日志使用了追加操作，是顺序写

4.语句更新完成，记录bin log，提交事务

补：redo 记录的是事务完成后的数据状态，undo记录的是事务完成前的数据状态

#### redo

执行sql，修改bufferPool中缓存页为脏页，修改redo记录某个数据页做了什么更改，redo持久化，(这个时候就算更新完成了)，后台线程定期刷新脏页到磁盘

redo是顺序写，数据写磁盘是随机写，因此redo的第二个作用在于，把随机写变成顺序写，提高性能，同时保证了崩溃回复的能力

redo也不是直接写到磁盘的，而是先写到redo log buffer(用户空间)，再到os buffer(内核空间,pageCache)，再到磁盘

刷盘时机：

- MySQL 正常关闭时；
- 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；
- InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。
- 每次**事务提交**时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘/都刷到pageCache(操作系统崩溃时丢失一秒数据)/不主动触发写入磁盘操作(MySQL进程崩溃时丢失一秒数据)

undo记录了修改前的数据状态，主要用于事务回滚

redo记录了修改后的状态，主要用于掉电回复。内存修改了undo 页面，也会记录到redo中，因为undo log也需要持久性

补：用户空间内存中的数据，一定要先写到pagecache中，再写到磁盘吗？否，一般先pageCache，但也可以直接读写磁盘，如数据库系统，有自己的缓存机制，可能希望绕过操作系统的 page cache，直接对磁盘进行读写，以避免数据在用户空间缓存和 page cache 之间的重复拷贝，提高 I/O 效率。

**redo和bin有什么区别**

redo 是循环写，日志空间大小固定，全写满就从头写，保存的是未刷盘的脏页日志，用于持久化，断电等故障恢复

bin是追加写，写满一个文件，创建一个新的文件接着写，保存的是全量数据，用于备份恢复，主从复制等

#### 主从复制

写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。

• 同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。

• 回放 Binlog：回放 binlog，并更新存储引擎中的数据。

主库一个 log dump 线程，从库创建一个专门的 I/O 线程，来接收主库的 binlog 日志，再把binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。

从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。（注意不是redo log，是relay log）

### 分布式

#### **主从复制和读写分离**

目的：分摊主库读压力，支持并发读 实现：读写分离需要依靠主从复制实现

具体实现：应用和数据之间加一个代理层，代理层分离读写请求，路由到对应的数据库中（sharing JDBC组件）

主从复制：依赖binlog实现，binlog记录了所有数据的变化（数据库执行的所有语句），主库发送binlog，从库接收并写到relay log中继日志(转发，接力)，返回给主库执行成功的响应；然后从库创建一个执行线程，更新数据 	**问题**：**过期读**（因为主从复制延迟）

解决方法：1.必须拿最新结果的请求，强制走主库	2.读从库之前，先sleep一下

#### 分库分表

**为什么要分库分表，如何进行分库分表**

垂直分库：不同的业务使用不同的数据库（用户数据库，订单数据库，商品数据库）

水平分库：和水平分表差不多，就是存到不同的库

水平分表：把一个表按**一定规则**拆分到不同的数据库中，订单表量太大，分到两个不同的表

​		查需要查多表，如果分库了，涉及到跨库事务和跨节点查询

垂直分表：对列进行拆分 



**垂直拆分**是把不同的表拆到不同的数据库中，而**水平拆分**是把同一个表拆到不同的数据库中

为什么垂直分表可以提高查询性能，因为是数据页储存，页大小固定，内容越少可以储存越多行数据，减少io次数

为什么：单表数据达到千万级以上，**读写越来越慢**  2.数据占用空间太大，**备份**时间越来越长 3.应用**并发**量太大

分片算法：哈希分片，求指定key的哈希，再确定数据该放到哪个表，适合随机读写，不适合需要范围查询

范围分片：按照特性的范围区间进行分表（id，时间等），适合范围查询，但可能出现热点数据的问题

**要考虑**分表字段，分表算法，全局id的设计 ---- **缺点**：跨库事务，查询复杂性，很难分页查询和排序

#### update的具体过程

数据加载到bufferPool；修改undo log记录旧值，这个日志修改记录到redo；修改数据页记录新值，修改记录到redo；后台选择时间把数据刷新到脏页

#### MYSQL的两段式提交

Two-Phase Commit，2PC（prepare+commit）。其实是分布式一致性协议，保证多个操作全成功或全失败，用于确保`redo log`和`bin log`的一致性

redo和bin不一致：

redo刷盘了，bin丢了：重启后，主库更新，从库没更新

bin刷盘了，redo丢了：重启后，认为事务无效，主库不更新，但从库发现有bin，执行了这个更新语句

本质上就是给redo加个状态，prepare和commit，如果bin未成功提交，redo回滚；如果bin成功提交，认为事务成功，重启后提交事务

补：事务没提交也可能会有redo刷盘，这时发现bin没提交，事务回滚

```
start_transaction()
try:
    execute_sql("")

    # 准备阶段
    # 将修改记录到redo log并标记为prepare
    write_redo_log("", status="prepare")
    flush_redo_log_to_disk()

    # 提交阶段
    # 将操作记录到bin log
    write_bin_log("INSERT INTO table_name (column1, column2) VALUES (value1, value2)")
    flush_bin_log_to_disk()

    # 将redo log状态改为commit
    update_redo_log_status(status="commit")

    # 提交事务
    commit_transaction()
    
except Exception as e:
    # 出现异常，回滚事务
    rollback_transaction()
```



**如何进行多表查询**（join）

select a.xx from table_a join table_b on a. ff = b.ff where xx

法2：子查询 select from where id = (select id from where ff =xx)

**如何对数据库进行优化**

优化索引（合理使用索引，避免过多索引）查询优化（避免select*，避免全表扫描，避免使用**join?**）

表结构优化（三范式，分库分表，选择合适得数据类型）

**储存引擎**（innodb和myisam的区别）

默认是innodb，支持**事务**，**聚簇索引**（数据放在主键索引的叶节点）所以必须有主键，主键索引效率高，二级索引需要回表，计算行数需要全表扫描

myisam主键叶节点放的是指针，主键索引和辅助索引是独立的，**保存表的具体行数**

InnoDB 最小的锁粒度是**行锁**，MyISAM 最小的锁粒度是**表锁**。

**MySQL多机高可用方案**

回答：针对读多写少的场景，主机器负责写操作，从机器负责读操作，数据由主机器同步到从机器；针对**写多读少**的场景，可以进行分库分表

**select count(1),count(*),count(列)**

前两一样，*的话如果不用where可能直接用元数据？最后一个不统计null，没索引的话可能会全表扫描

1和*可能用主键索引，也可能二级，二级开销会小一些，具体要看explain，看优化器咋选



#### **常用操作**

sql执行顺序  FROM - ON - JOIN - **WHERE** - GROUP BY（开始使用select中的别名，后面都可以使用）avg/sum - WITH - **HAVING** - **SELECT** - DISTINCT - ORDER BY - LIMIT

结果去重：distinct，

限制结果返回行数：limit（偏移量，总行数）select filed from t limt (m,n)（从m加1开始，取n条数据）

查询后的列重命名：（select 列 as（可省） newName from t）

查找后排序：order by（asc(ascend)/desc），默认升序

查找后多列排序(order by gpa asc,age asc) 

条件查找：where，字符串别忘了加''

范围查找：where age>=20and age<=23~~~where age between 20 and 23(包含两个端点)***where age in(20,21,22,23)(别忘了括号)

排除某条信息 WHERE  university not in ('复旦大学‘)(列名 [``NOT``] ``IN``（常量1, 常量2,…常量n）)/where university!='aa'

涉及空值的查询：列名 is null/is not null

查最高值 select max(filed) from t~~~(其他聚合函数 max COUNT AVG)

round(a,1)查询字段a，结果保留一位小数

聚合函数结果作为筛选条件时，不能用where，而是用（having**分组过滤**）

更新：update 表 set 字段 = ‘新值’ where

**条件函数**：相当于查age那列，小于25的话单元格的值就是' 25岁以下'  case when then

```
case 
when age<25 or age is null then '25岁以下'
when age>=25 then '25岁及以上'
(else)	end (age_cut命名),
```

**算子**：在表达式中执行操作的符号或关键字
`SELECT`是一个用于选择列的算子，`WHERE`是一个用于过滤行的算子，`JOIN`是用于连接表的算子等

补：select * from t_table where a > 1 and b = 2 a字段用了联合索引，b字段没走

where a >= 1 and b = 2，a，b字段都用了联合索引，会从符合 a = 1 and b = 2 条件的第一条记录开始扫描

